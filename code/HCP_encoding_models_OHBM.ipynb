{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb2c180-cd38-4468-8294-61c2c87a6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import analysis\n",
    "import hrf_tools\n",
    "import numpy as np\n",
    "from utility import mask_cifti,unmask_cifti\n",
    "from analysis import get_vertex_info_59k,simple_ridgeCV,plot_results\n",
    "import hrf_tools\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import matplotlib\n",
    "#matplotlib.rcParams['figure.figsize'] = (6, 4)\n",
    "# this is run by run_datalad_run_encoding_model.sh\n",
    "# \"python ./run_encoding_model.py $sub $2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4371dc6d-c0f0-45fb-8226-170329e1a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plan\n",
    "# 1: extract auditory areas (?)\n",
    "\n",
    "#no... these are just the surface and don't match up exactly with the cifti\n",
    "\n",
    "# run model on just specific features and combine across movies?\n",
    "# plot results of specific features\n",
    "\n",
    "\n",
    "# 2 extract primary auditory cortex\n",
    "# get mfs features? (coarse)\n",
    "# try to plot tonotopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febeefd-bf60-49e7-95f8-397b410ab4e8",
   "metadata": {},
   "source": [
    "## get EARLY AC and ALL AC from all subjects - store eachon scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fee99-527b-4fb7-aacc-c135823aa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfile = open(\"HCP_7T_subjects.txt\", \"r\")\n",
    "sublist = [(line.strip()).split() for line in subfile]\n",
    "sublist = [item for s in sublist for item in s]\n",
    "\n",
    "feature='mfs'\n",
    "dataset='HCP_7T'\n",
    "n_movies=[1,2,3,4]\n",
    "#X_all=[]\n",
    "#X_all_4=[]\n",
    "Y_all=[]\n",
    "Y_all_early=[]\n",
    "subject_list=[]\n",
    "\n",
    "for i,subject in enumerate(sublist):\n",
    "    print(f'{i+1} of {len(sublist)}')\n",
    "    \n",
    "    try:\n",
    "        X,Y,vertex_info = analysis.load_data_HCP(subject,feature,n_movies)\n",
    "        #X_all.append(X)\n",
    "        #X_new=np.zeros((X.shape[0],4))\n",
    "#         for i in np.arange(4):\n",
    "#             start=i*32\n",
    "#             stop=(i*32)+32\n",
    "#             X_new[:,i]=np.mean(X[:,start:stop],axis=1)\n",
    "        Y_AC=mask_cifti(auditory_59k,Y)\n",
    "        Y_AC_early=mask_cifti(early_auditory_59k,Y)\n",
    "\n",
    "#         X_all_4.append(X_new)\n",
    "#         Y_all.append(Y_new)\n",
    "#         Y_all_early.append(Y_new_early)\n",
    "        subject_list.append(subject)\n",
    "    except:\n",
    "        print(f'file dne, skipping {subject}')\n",
    "        continue\n",
    "# np.save('/om/scratch/Thu/jsmentch/X_all.npy',X_all) #this is all mfs features\n",
    "# np.save('/om/scratch/Thu/jsmentch/X_all_4.npy',X_all_4) #this is the same features but combined into 4 bins\n",
    "\n",
    "    np.save(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/AC/{subject}.npy',Y_AC) #this is early and association AC\n",
    "    np.save(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/AC_early/{subject}.npy',Y_AC_early) #this is early AC\n",
    "np.save('/om/scratch/Thu/jsmentch/HCP_7T_rois/subject_list.npy',subject_list) #this is the list of subjects that we were able to get data from\n",
    "\n",
    "#### to convert old list of arrays of mfs features to a single mfs feature because they are the same for all subjects\n",
    "# X_all=np.load('/om/scratch/Thu/jsmentch/X_all.npy') #this is all mfs features\n",
    "# X_all_4=np.load('/om/scratch/Thu/jsmentch/X_all_4.npy') #this is the same features but combined into 4 bins\n",
    "# X_all=X_all[0]\n",
    "# X_all_4=X_all_4[0]\n",
    "# print(X_all.shape,X_all_4.shape)\n",
    "# np.save(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/mfs_all.npy',X_all)\n",
    "# np.save(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/mfs_4.npy',X_all_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0df796f-21b5-49f3-871c-5b6c569edd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "#save the other AS features in the same way as mfs above concatenated across movies\n",
    "features=['chroma', 'mfcc', 'mfs', 'as_embed', 'as_scores']\n",
    "subject=100610\n",
    "dataset='HCP_7T'\n",
    "for feature in features:\n",
    "    n_movies=[1,2,3,4]\n",
    "    X,Y,vertex_info = analysis.load_data_HCP(subject,feature,n_movies)\n",
    "\n",
    "    np.save(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/{feature}.npy',X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01ff0f-ab0d-4fa8-90ed-78c13ee7ec4e",
   "metadata": {},
   "source": [
    "## run encoding model - train on all subs except 1, test on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d23149a-eaed-40bb-a47a-eaf468096f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmp_59k=np.load('../sourcedata/data/parcellations/mmp_59k.npy' )\n",
    "early_auditory_59k=np.load('../sourcedata/data/parcellations/early_auditory_59k.npy' )\n",
    "auditory_59k=np.load('../sourcedata/data/parcellations/auditory_59k.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0047ae76-1dd4-41b9-ab39-cbd1d76a6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_info=get_vertex_info_59k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9484ed-c761-4fb3-a635-f3fe5ce4a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['chroma', 'mfcc', 'mfs', 'as_embed', 'as_scores']\n",
    "\n",
    "subject_list=np.load('/om/scratch/Thu/jsmentch/HCP_7T_rois/subject_list.npy') #this is the list of subjects that we were able to get data from\n",
    "mfs_all=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/mfs_all.npy')\n",
    "mfs_4=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/mfs_4.npy')\n",
    "chroma=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/chroma.npy')\n",
    "mfcc=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/mfs_4.npy')\n",
    "as_embed=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/as_embed.npy')\n",
    "as_scores=np.load(f'/om/scratch/Thu/jsmentch/HCP_7T_rois/as_scores.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f852f6-6849-4204-8453-1cc13c5f889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7bbcbc9-06dc-472c-8287-84d6ca849750",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature='as_scores'\n",
    "num_sub=20\n",
    "\n",
    "#apply HRF and standard scale X feature\n",
    "scaler = StandardScaler()\n",
    "X_h= hrf_tools.apply_optimal_hrf_10hz(as_scores,1)\n",
    "X_s = scaler.fit_transform(X=X_h,y=None)\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "for subject in subject_list[0:num_sub]:\n",
    "    X.append(X_s)\n",
    "    Y_=np.load (f'/om/scratch/Thu/jsmentch/HCP_7T_rois/AC/{subject}.npy') \n",
    "    Y.append(Y_)\n",
    "#Y = np.load ('/om/scratch/Thu/jsmentch/Y_all.npy') #this is all AC\n",
    "Y=np.concatenate(Y)\n",
    "X=np.concatenate(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14197ab8-821f-447c-8c1b-77236d24c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mean,corr_mean,weights_mean=simple_ridgeCV(X,Y,num_sub)\n",
    "scores_mean_unmasked=unmask_cifti(auditory_59k,scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ba5d1c-9d84-4498-9fce-c3d30d702204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/gablab/jsmentch/projects/nat_img/code/nilearn_plotting_custom.py:184: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  axes = Axes3D(figure, rect=[0, 0, 1, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01599029 -0.01565468 -0.01546848 ...  0.43341737  0.43373959\n",
      "  0.43691689]\n",
      "[-0.0196055  -0.01960466 -0.0193408  ...  0.3793563   0.39278789\n",
      "  0.39485723]\n",
      "[-0.01599029 -0.01565468 -0.01546848 ...  0.43341737  0.43373959\n",
      "  0.43691689]\n",
      "[-0.0196055  -0.01960466 -0.0193408  ...  0.3793563   0.39278789\n",
      "  0.39485723]\n"
     ]
    }
   ],
   "source": [
    "plot_results(scores_mean_unmasked,'r2','59k',vertex_info,'hcp_test',feature,'HCP_7T',f'{num_sub}_sub_cv{num_sub}_AC_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974c7b9-c1f8-48e8-ab0b-d360c492a309",
   "metadata": {},
   "source": [
    "## run encoding model - train on all subs 3 movies, test on 1 movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804ff22-c906-4c84-a814-f2ea46fe0053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
