{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "official-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import nilearn.image as image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-match",
   "metadata": {},
   "source": [
    "## first extract the timecourses from MMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recent-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate them into one np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "waiting-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also get class and save it into another array with zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "taken-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/om2/scratch/Fri/jsmentch/nat_img/sourcedata/data/HBN/brain/clean/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "extended-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per Usman, \n",
    "# The input file should be of shape (N*R*T) where\n",
    "# N = number of subjects,\n",
    "# R = number of components/regions,\n",
    "# T = number of time-points. \n",
    "\n",
    "# session should be one of movieDM, movieTP, rest_run-1, rest_run-2\n",
    "# movie_length is expected number of TRs and it will chop off the rest...\n",
    "# should be 750, 250, 375, 375\n",
    "\n",
    "def get_mmp_data(session, movie_length):\n",
    "    sub_list=[]\n",
    "    ses_list=[]\n",
    "    dx_list=[]\n",
    "    mmp_data=[]\n",
    "\n",
    "\n",
    "    for file in glob.glob(f'{path}*/*/*movieDM*.ptseries.nii'):\n",
    "        #print(file)\n",
    "        img = image.load_img(file).get_fdata()\n",
    "        img = np.array(img.tolist())\n",
    "\n",
    "        mmp_data.append( img[:movie_length,:] )\n",
    "        head,filename=os.path.split(file)\n",
    "        head,ses=os.path.split(head)\n",
    "        head,sub=os.path.split(head)\n",
    "        sub_list.append(sub)\n",
    "        ses_list.append(ses)\n",
    "\n",
    "        if f\"{sub}\" in open('hbn_asc_50.txt').read():\n",
    "            dx_list.append(1)#ASC\n",
    "        else:\n",
    "            dx_list.append(0)#NT\n",
    "    #dm_mmp_data=np.asarray(dm_mmp_data)\n",
    "    mmp_data=np.dstack(mmp_data)\n",
    "    mmp_data=np.transpose(mmp_data,(2,1,0))\n",
    "    return sub_list, ses_list, dx_list, mmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "handmade-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='../sourcedata/data/HBN/brain/clean/for_dice/'\n",
    "\n",
    "for session, movie_length in [('movieDM', 750), ('movieTP', 250), ('rest_run-1', 375), ('rest_run-2', 375) ]:\n",
    "    sub_list, ses_list, dx_list, mmp_data=get_mmp_data(session, movie_length)\n",
    "    np.savez(f'{output_dir}{session}.npz', sub_list, ses_list, dx_list, mmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "lesbian-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 360)\n",
      "(250, 360)\n",
      "(250, 360)\n",
      "(250, 360)\n",
      "(250, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n",
      "(375, 360)\n"
     ]
    }
   ],
   "source": [
    "#print expected number of TRs\n",
    "    \n",
    "for file in glob.glob(f'{path}*/*/*movieTP*.ptseries.nii')[:5]:\n",
    "    img = image.load_img(file).get_fdata()\n",
    "    print(img.shape)\n",
    "for file in glob.glob(f'{path}*/*/*rest_run-1*.ptseries.nii')[:5]:\n",
    "    img = image.load_img(file).get_fdata()\n",
    "    print(img.shape)    \n",
    "for file in glob.glob(f'{path}*/*/*rest_run-2*.ptseries.nii')[:5]:\n",
    "    img = image.load_img(file).get_fdata()\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-mandate",
   "metadata": {},
   "source": [
    "## Now extract timecourses from Tensor Decomposition's spatial maps?\n",
    "unclear if this is the right thing to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how correlated each subject is to each spatial component at each time point -> this is the time course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "awful-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movieDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_file='/om2/scratch/Fri/jsmentch/nascar_data/output/results_movieDM.mat'\n",
    "#mat_contents = loadmat(outputs_file, squeeze_me=True, simplify_cells = True)\n",
    "mat_contents = loadmat(outputs_file)\n",
    "rank=19\n",
    "components_DM=mat_contents['result']['U'][0,rank][0,0]\n",
    "temporal_modes_DM=mat_contents['result']['U'][0,rank][1,0]\n",
    "contributions_DM=mat_contents['result']['U'][0,rank][2,0]\n",
    "\n",
    "meta_file='/om2/scratch/Fri/jsmentch/nascar_data/input/movieDM_meta.mat'\n",
    "mat_contents = loadmat(meta_file)\n",
    "dx_list_DM=mat_contents['dx_list'].squeeze()\n",
    "sub_list_DM=mat_contents['sub_list']\n",
    "ses_list_DM=mat_contents['ses_list']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
