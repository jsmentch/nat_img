{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/hbn/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 13.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imaging_site(identifier):\n",
    "    path = f'/nese/mit/group/sig/projects/hbn/hbn_bids/sub-{identifier}/'\n",
    "    if os.path.isdir(path + 'ses-HBNsiteRU'):\n",
    "        return 'RU'\n",
    "    elif os.path.isdir(path + 'ses-HBNsiteCBIC'):\n",
    "        return 'CBIC'\n",
    "    elif os.path.isdir(path + 'ses-HBNsiteSI'):\n",
    "        return 'SI'\n",
    "    elif os.path.isdir(path + 'ses-HBNsiteCUNY'):\n",
    "        return 'CUNY'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_final=pd.read_csv('/nese/mit/group/sig/projects/naturalistic/nat_img/sourcedata/data/HBN/phenotype/parsed/dx_onehot.csv')\n",
    "dx_final['imaging_site'] = dx_final['Identifiers'].apply(get_imaging_site)\n",
    "#asd_df = dx_final[dx_final['Autism Spectrum Disorder'] == 1][['Identifiers']]\n",
    "filtered_df = dx_final[dx_final['Autism Spectrum Disorder'] == 1]\n",
    "asd_df = filtered_df[['Identifiers','imaging_site']].rename(columns={'Identifiers': 'subj_id'})\n",
    "asd_df['subj_id'] = 'sub-' + asd_df['subj_id'].astype(str)\n",
    "#nt_df = dx_final[dx_final['No Diagnosis Given'] == 1][['Identifiers']]\n",
    "filtered_df = dx_final[dx_final['No Diagnosis Given'] == 1]\n",
    "nt_df = filtered_df[['Identifiers','imaging_site']].rename(columns={'Identifiers': 'subj_id'})\n",
    "nt_df['subj_id'] = 'sub-' + nt_df['subj_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>imaging_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-NDARAA075AMK</td>\n",
       "      <td>SI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sub-NDARAA773LUW</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sub-NDARAB653ZXP</td>\n",
       "      <td>CBIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sub-NDARAC904DMU</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sub-NDARAE012DGA</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>sub-NDARZV421TCZ</td>\n",
       "      <td>CBIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>sub-NDARZV983XK9</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>sub-NDARZW363UGM</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>sub-NDARZW623WYG</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>sub-NDARZX384XVQ</td>\n",
       "      <td>CBIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               subj_id imaging_site\n",
       "0     sub-NDARAA075AMK           SI\n",
       "7     sub-NDARAA773LUW         None\n",
       "17    sub-NDARAB653ZXP         CBIC\n",
       "30    sub-NDARAC904DMU           RU\n",
       "41    sub-NDARAE012DGA           RU\n",
       "...                ...          ...\n",
       "3987  sub-NDARZV421TCZ         CBIC\n",
       "3992  sub-NDARZV983XK9           RU\n",
       "3995  sub-NDARZW363UGM           RU\n",
       "4000  sub-NDARZW623WYG         None\n",
       "4011  sub-NDARZX384XVQ         CBIC\n",
       "\n",
       "[373 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to Yibei's controls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [9,8,7]:\n",
    "#     yibei_nt=pd.read_csv(f'../../hbn_adhd/code/control_subs_test{i}.csv')\n",
    "#     #yibei_nt['subj_id'] = 'sub-' + yibei_nt['subj_id'].astype(str)\n",
    "#     nt_test=yibei_nt.merge(dx_final, on=\"Identifiers\", how='inner')\n",
    "#     df_selected = nt_test.iloc[:, 4:]\n",
    "#     nt_test_sum = df_selected.sum()\n",
    "#     nt_test_sum = nt_test_sum[nt_test_sum != 0]\n",
    "#     print(f'\\n~+~+~+~+~+~+~+~+~+~THRESHOLD={i}')\n",
    "#     print(nt_test_sum.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## load qc data and save as csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "\n",
    "base_dir = os.getenv(\"BASE_DIR\")\n",
    "base_dir='/nese/mit/group/sig/projects/hbn/'\n",
    "#project_dir = os.getenv(\"PROJECT_DIR\")\n",
    "project_dir='/nese/mit/group/sig/projects/hbn/'\n",
    "data_dir = os.path.join(project_dir, \"hbn_bids\", \"derivatives\")\n",
    "#output_dir = os.path.join(base_dir, \"fmri\", \"output\")\n",
    "#save_dir = os.path.join(output_dir, \"qc\")\n",
    "#os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2csv(files):\n",
    "    \"\"\"\n",
    "    Reads a list of JSON files, transposes each file, and concatenates the results into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - files (list of str): List of paths to the JSON files.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A concatenated DataFrame of the transposed JSON files.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        # Read with pandas, transpose, and convert to Dask DataFrame\n",
    "        subj_id = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "        task = file.split(\"/\")[-1].split(\"_\")[-2]\n",
    "        df = pd.read_json(file, orient='index').T\n",
    "        df[\"subj_id\"] = subj_id\n",
    "        df[\"task\"] = task\n",
    "        dask_df = dd.from_pandas(df, npartitions=1)\n",
    "        dfs.append(dask_df)\n",
    "\n",
    "    # Concatenate all the Dask DataFrames\n",
    "    concat_df = dd.concat(dfs).compute()\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDM_qc_files = glob.glob(os.path.join(data_dir, \"mriqc_23.1.0\", \"sub-*\",  \"*\", \"func\", \"*task-movieDM*.json\"))\n",
    "movieDM_qc_files.sort()\n",
    "movieTP_qc_files = glob.glob(os.path.join(data_dir, \"mriqc_23.1.0\", \"sub-*\",  \"*\", \"func\", \"*task-movieTP*.json\"))\n",
    "movieTP_qc_files.sort()\n",
    "rest1_qc_files = glob.glob(os.path.join(data_dir, \"mriqc_23.1.0\", \"sub-*\",  \"*\", \"func\", \"*task-rest_run-1*.json\"))\n",
    "rest1_qc_files.sort()\n",
    "rest2_qc_files = glob.glob(os.path.join(data_dir, \"mriqc_23.1.0\", \"sub-*\",  \"*\", \"func\", \"*task-rest_run-2*.json\"))\n",
    "rest2_qc_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDM_qc = json2csv(movieDM_qc_files)\n",
    "movieTP_qc = json2csv(movieTP_qc_files)\n",
    "rest1_qc = json2csv(rest1_qc_files)\n",
    "rest2_qc = json2csv(rest2_qc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqms = ['subj_id',\"aor\", \"aqi\", 'dvars_nstd', 'dvars_std', 'dvars_vstd', 'efc', \n",
    "        'fber', 'fd_mean', 'fd_num', 'fd_perc', 'fwhm_avg', 'gcor', \n",
    "        'gsr_x', 'gsr_y', 'snr', 'spacing_tr', 'tsnr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDM_qc.to_csv(os.path.join(\"movieDM_qc.csv\"), index=False)\n",
    "movieTP_qc.to_csv(os.path.join(\"movieTP_qc.csv\"), index=False)\n",
    "rest1_qc.to_csv(os.path.join(  \"rest1_qc.csv\"  ), index=False)\n",
    "rest2_qc.to_csv(os.path.join(  \"rest2_qc.csv\"  ), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load saved qc csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDM_qc = pd.read_csv(\"../sourcedata/data/HBN/phenotype/movieDM_qc.csv\")\n",
    "movieTP_qc = pd.read_csv(\"../sourcedata/data/HBN/phenotype/movieTP_qc.csv\")\n",
    "rest1_qc = pd.read_csv(  \"../sourcedata/data/HBN/phenotype/rest1_qc.csv\"  )\n",
    "rest2_qc = pd.read_csv(  \"../sourcedata/data/HBN/phenotype/rest2_qc.csv\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(df):\n",
    "    df = df.apply(lambda col: col.astype(float) if col.name != 'subj_id' else col)\n",
    "    return df\n",
    "\n",
    "iqms = ['subj_id',\"aor\", \"aqi\", 'dvars_nstd', 'dvars_std', 'dvars_vstd', 'efc', \n",
    "        'fber', 'fd_mean', 'fd_num', 'fd_perc', 'fwhm_avg', 'gcor', \n",
    "        'gsr_x', 'gsr_y', 'snr', 'spacing_tr', 'tsnr']\n",
    "\n",
    "dm_qc = convert_to_float(  movieDM_qc[iqms] )\n",
    "tp_qc = convert_to_float(  movieTP_qc[iqms] )\n",
    "r1_qc = convert_to_float(  rest1_qc[iqms] )\n",
    "r2_qc = convert_to_float(  rest2_qc[iqms] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2618 w/ any fmriprepped data (333 ASD, 178 NT)\n",
      "----Site RU: 139 ASD, 106 NT\n",
      "----Site CUNY: 31 ASD, 15 NT\n",
      "----Site CBIC: 163 ASD, 57 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 302 ASD, 163 NT\n",
      "1734 w/ all 4 runs (213 ASD, 103 NT )\n",
      "----Site RU: 84 ASD, 61 NT\n",
      "----Site CUNY: 26 ASD, 9 NT\n",
      "----Site CBIC: 103 ASD, 33 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 187 ASD, 94 NT\n",
      "2274 w/ at least DM (288 ASD, 162 NT )\n",
      "----Site RU+CBIC: 259 ASD, 148 NT\n",
      "1883 w/ at least DM and 1 resting state (232 ASD, 108 NT )\n",
      "----Site RU+CBIC: 203 ASD, 99 NT\n",
      "1785 w/ at least DM and both resting state (223 ASD, 106 NT )\n",
      "----Site RU+CBIC: 196 ASD, 97 NT\n"
     ]
    }
   ],
   "source": [
    "def count_subjects(dm_qc,tp_qc,r1_qc,r2_qc):\n",
    "    dm_qc_subj_id = dm_qc[['subj_id']]\n",
    "    tp_qc_subj_id = tp_qc[['subj_id']]\n",
    "    r1_qc_subj_id = r1_qc[['subj_id']]\n",
    "    r2_qc_subj_id = r2_qc[['subj_id']]\n",
    "    \n",
    "    ###### See how many subjects (union)\n",
    "    combined_df = pd.concat([dm_qc_subj_id, tp_qc_subj_id, r1_qc_subj_id, r2_qc_subj_id])\n",
    "    subjs_anyruns = combined_df.drop_duplicates()\n",
    "\n",
    "    asd_any_runs=subjs_anyruns.merge(asd_df, on=\"subj_id\", how='inner')\n",
    "    nt_any_runs=subjs_anyruns.merge(nt_df, on=\"subj_id\", how='inner')\n",
    "\n",
    "    print(f\"{len(subjs_anyruns)} w/ any fmriprepped data ({len(asd_any_runs)} ASD, {len(nt_any_runs)} NT)\")\n",
    "    \n",
    "    values = ['RU','CUNY','CBIC','SI']\n",
    "    filtered_df = asd_any_runs[asd_any_runs['imaging_site'].isin(values)]\n",
    "    counts_asd = filtered_df['imaging_site'].value_counts()\n",
    "    filtered_df = nt_any_runs[nt_any_runs['imaging_site'].isin(values)]\n",
    "    counts_nt = filtered_df['imaging_site'].value_counts()\n",
    "    for v in values:\n",
    "        #print(f\"v= {v},{counts_asd} \")\n",
    "        try:\n",
    "            print(f\"----Site {v}: {counts_asd[v]} ASD, {counts_nt[v]} NT\")\n",
    "        except:\n",
    "            print(f\"----Site {v}: a group has 0\")\n",
    "            #pass\n",
    "    print(f\"----Site RU+CBIC: {counts_asd['RU']+counts_asd['CBIC']} ASD, {counts_nt['RU']+counts_nt['CBIC']} NT\")\n",
    "    \n",
    "    ####### see how many have all 4 runs\n",
    "    subjs_allruns = dm_qc_subj_id.merge(tp_qc_subj_id, on=\"subj_id\", how='inner').merge(r1_qc_subj_id, on=\"subj_id\", how='inner').merge(r2_qc_subj_id, on=\"subj_id\", how='inner')\n",
    "    num_common_rows = len(subjs_allruns)\n",
    "\n",
    "    asd_all_runs=subjs_allruns.merge(asd_df, on=\"subj_id\", how='inner')\n",
    "    nt_all_runs=subjs_allruns.merge(nt_df, on=\"subj_id\", how='inner')\n",
    "\n",
    "    print(f\"{num_common_rows} w/ all 4 runs ({len(asd_all_runs)} ASD, {len(nt_all_runs)} NT )\")\n",
    "\n",
    "\n",
    "    values = ['RU','CUNY','CBIC','SI']\n",
    "    filtered_df = asd_all_runs[asd_all_runs['imaging_site'].isin(values)]\n",
    "    counts_asd = filtered_df['imaging_site'].value_counts()\n",
    "    filtered_df = nt_all_runs[nt_all_runs['imaging_site'].isin(values)]\n",
    "    counts_nt = filtered_df['imaging_site'].value_counts()\n",
    "    \n",
    "    for v in values:\n",
    "        try: print(f\"----Site {v}: {counts_asd[v]} ASD, {counts_nt[v]} NT\")\n",
    "        except:\n",
    "            print(f\"----Site {v}: a group has 0\")\n",
    "            #pass\n",
    "    print(f\"----Site RU+CBIC: {counts_asd['RU']+counts_asd['CBIC']} ASD, {counts_nt['RU']+counts_nt['CBIC']} NT\")\n",
    "\n",
    "    ###### see how many have at least despicable me\n",
    "    target_df = dm_qc_subj_id\n",
    "\n",
    "    num_common_rows = len(target_df)\n",
    "    \n",
    "    asd_target_df=target_df.merge(asd_df, on=\"subj_id\", how='inner')\n",
    "    nt_target_df=target_df.merge(nt_df, on=\"subj_id\", how='inner')\n",
    "\n",
    "    values = ['RU','CUNY','CBIC','SI']\n",
    "    filtered_df = asd_target_df[asd_target_df['imaging_site'].isin(values)]\n",
    "    counts_asd = filtered_df['imaging_site'].value_counts()\n",
    "    filtered_df = nt_target_df[nt_target_df['imaging_site'].isin(values)]\n",
    "    counts_nt = filtered_df['imaging_site'].value_counts()\n",
    "    \n",
    "    print(f\"{num_common_rows} w/ at least DM ({len(asd_target_df)} ASD, {len(nt_target_df)} NT )\")\n",
    "    print(f\"----Site RU+CBIC: {counts_asd['RU']+counts_asd['CBIC']} ASD, {counts_nt['RU']+counts_nt['CBIC']} NT\")\n",
    "    \n",
    "\n",
    "    ###### see how many have at least one resting state and DM\n",
    "    target_df = pd.merge(dm_qc_subj_id, r1_qc_subj_id, on=\"subj_id\", how=\"inner\")\n",
    "    target_df2 = pd.merge(dm_qc_subj_id, r2_qc_subj_id, on=\"subj_id\", how=\"inner\")\n",
    "    \n",
    "    target_df = pd.merge(target_df, target_df2, on=\"subj_id\", how=\"outer\")\n",
    "    num_common_rows = len(target_df)\n",
    "    \n",
    "    asd_target_df=target_df.merge(asd_df, on=\"subj_id\", how='inner')\n",
    "    nt_target_df=target_df.merge(nt_df, on=\"subj_id\", how='inner')\n",
    "\n",
    "    values = ['RU','CUNY','CBIC','SI']\n",
    "    filtered_df = asd_target_df[asd_target_df['imaging_site'].isin(values)]\n",
    "    counts_asd = filtered_df['imaging_site'].value_counts()\n",
    "    filtered_df = nt_target_df[nt_target_df['imaging_site'].isin(values)]\n",
    "    counts_nt = filtered_df['imaging_site'].value_counts()\n",
    "    \n",
    "    print(f\"{num_common_rows} w/ at least DM and 1 resting state ({len(asd_target_df)} ASD, {len(nt_target_df)} NT )\")\n",
    "    print(f\"----Site RU+CBIC: {counts_asd['RU']+counts_asd['CBIC']} ASD, {counts_nt['RU']+counts_nt['CBIC']} NT\")\n",
    "\n",
    "    ###### see how many have at least both resting state and DM\n",
    "    target_df = dm_qc_subj_id.merge(r1_qc_subj_id, on=\"subj_id\", how='inner').merge(r2_qc_subj_id, on=\"subj_id\", how='inner')\n",
    "\n",
    "    num_common_rows = len(target_df)\n",
    "    \n",
    "    asd_target_df=target_df.merge(asd_df, on=\"subj_id\", how='inner')\n",
    "    nt_target_df=target_df.merge(nt_df, on=\"subj_id\", how='inner')\n",
    "\n",
    "    values = ['RU','CUNY','CBIC','SI']\n",
    "    filtered_df = asd_target_df[asd_target_df['imaging_site'].isin(values)]\n",
    "    counts_asd = filtered_df['imaging_site'].value_counts()\n",
    "    filtered_df = nt_target_df[nt_target_df['imaging_site'].isin(values)]\n",
    "    counts_nt = filtered_df['imaging_site'].value_counts()\n",
    "    \n",
    "    print(f\"{num_common_rows} w/ at least DM and both resting state ({len(asd_target_df)} ASD, {len(nt_target_df)} NT )\")\n",
    "    print(f\"----Site RU+CBIC: {counts_asd['RU']+counts_asd['CBIC']} ASD, {counts_nt['RU']+counts_nt['CBIC']} NT\")\n",
    "\n",
    "    \n",
    "    return subjs_anyruns,subjs_allruns\n",
    "\n",
    "\n",
    "anyruns,allruns=count_subjects(dm_qc,tp_qc,r1_qc,r2_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter out based on Yibei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389 w/ any fmriprepped data (170 ASD, 107 NT)\n",
      "----Site RU: 77 ASD, 66 NT\n",
      "----Site CUNY: 16 ASD, 5 NT\n",
      "----Site CBIC: 77 ASD, 36 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 154 ASD, 102 NT\n",
      "378 w/ all 4 runs (39 ASD, 29 NT )\n",
      "----Site RU: 18 ASD, 22 NT\n",
      "----Site CUNY: 5 ASD, 1 NT\n",
      "----Site CBIC: 16 ASD, 6 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 34 ASD, 28 NT\n",
      "837 w/ at least DM (99 ASD, 66 NT )\n",
      "----Site RU+CBIC: 89 ASD, 63 NT\n",
      "617 w/ at least DM and 1 resting state (72 ASD, 42 NT )\n",
      "----Site RU+CBIC: 63 ASD, 41 NT\n",
      "509 w/ at least DM and both resting state (57 ASD, 34 NT )\n",
      "----Site RU+CBIC: 50 ASD, 33 NT\n"
     ]
    }
   ],
   "source": [
    "def yibei_filter(df_in):\n",
    "    dm_mean_fd_perc = df_in['fd_perc'].mean()\n",
    "    dm1 = df_in[df_in['fd_perc'] < dm_mean_fd_perc]\n",
    "    \n",
    "    dm_mean_tsnr = df_in['tsnr'].mean()\n",
    "    dm2 = dm1[dm1['tsnr'] > dm_mean_tsnr]\n",
    "    return dm2\n",
    "\n",
    "dm_qc_yibei=yibei_filter(dm_qc)\n",
    "tp_qc_yibei=yibei_filter(tp_qc)\n",
    "r1_qc_yibei=yibei_filter(r1_qc)\n",
    "r2_qc_yibei=yibei_filter(r2_qc)\n",
    "\n",
    "anyruns,allruns=count_subjects(dm_qc_yibei,tp_qc_yibei,r1_qc_yibei,r2_qc_yibei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter out based on dorit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416 w/ any fmriprepped data (173 ASD, 100 NT)\n",
      "----Site RU: 69 ASD, 59 NT\n",
      "----Site CUNY: 17 ASD, 4 NT\n",
      "----Site CBIC: 87 ASD, 37 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 156 ASD, 96 NT\n",
      "453 w/ all 4 runs (56 ASD, 32 NT )\n",
      "----Site RU: 25 ASD, 20 NT\n",
      "----Site CUNY: 6 ASD, 1 NT\n",
      "----Site CBIC: 25 ASD, 11 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 50 ASD, 31 NT\n",
      "871 w/ at least DM (106 ASD, 67 NT )\n",
      "----Site RU+CBIC: 96 ASD, 66 NT\n",
      "649 w/ at least DM and 1 resting state (72 ASD, 42 NT )\n",
      "----Site RU+CBIC: 63 ASD, 41 NT\n",
      "528 w/ at least DM and both resting state (63 ASD, 37 NT )\n",
      "----Site RU+CBIC: 54 ASD, 36 NT\n"
     ]
    }
   ],
   "source": [
    "def dorit_filter(df_in):\n",
    "    #If the number of timepoints with a mean FD > 0.2mm is greater than 40% per individual the subject will be excluded \n",
    "    dm1 = df_in[df_in['fd_perc'] < 40]\n",
    "    \n",
    "    # dm_mean_tsnr = df_in['tsnr'].mean()\n",
    "    # dm2 = dm1[dm1['tsnr'] > dm_mean_tsnr]\n",
    "    return dm1\n",
    "\n",
    "dm_qc_dorit=dorit_filter(dm_qc)\n",
    "tp_qc_dorit=dorit_filter(tp_qc)\n",
    "r1_qc_dorit=dorit_filter(r1_qc)\n",
    "r2_qc_dorit=dorit_filter(r2_qc)\n",
    "\n",
    "anyruns,allruns=count_subjects(dm_qc_dorit,\n",
    "                               tp_qc_dorit,\n",
    "                               r1_qc_dorit,\n",
    "                               r2_qc_dorit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter out based on only yibei FD filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621 w/ any fmriprepped data (194 ASD, 120 NT)\n",
      "----Site RU: 79 ASD, 72 NT\n",
      "----Site CUNY: 18 ASD, 5 NT\n",
      "----Site CBIC: 97 ASD, 43 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 176 ASD, 115 NT\n",
      "584 w/ all 4 runs (67 ASD, 39 NT )\n",
      "----Site RU: 26 ASD, 25 NT\n",
      "----Site CUNY: 7 ASD, 1 NT\n",
      "----Site CBIC: 34 ASD, 13 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 60 ASD, 38 NT\n",
      "1100 w/ at least DM (131 ASD, 85 NT )\n",
      "----Site RU+CBIC: 118 ASD, 82 NT\n",
      "819 w/ at least DM and 1 resting state (96 ASD, 51 NT )\n",
      "----Site RU+CBIC: 84 ASD, 50 NT\n",
      "696 w/ at least DM and both resting state (79 ASD, 44 NT )\n",
      "----Site RU+CBIC: 69 ASD, 43 NT\n"
     ]
    }
   ],
   "source": [
    "def yibei_lax_filter(df_in):\n",
    "    dm_mean_fd_perc = df_in['fd_perc'].mean()\n",
    "    dm2 = df_in[df_in['fd_perc'] < dm_mean_fd_perc]\n",
    "    \n",
    "    # dm_mean_tsnr = df_in['tsnr'].mean()\n",
    "    # dm2 = dm1[dm1['tsnr'] > dm_mean_tsnr]\n",
    "    return dm2\n",
    "\n",
    "dm_qc_yibei=yibei_lax_filter(dm_qc)\n",
    "tp_qc_yibei=yibei_lax_filter(tp_qc)\n",
    "r1_qc_yibei=yibei_lax_filter(r1_qc)\n",
    "r2_qc_yibei=yibei_lax_filter(r2_qc)\n",
    "\n",
    "anyruns,allruns=count_subjects(dm_qc_yibei,tp_qc_yibei,r1_qc_yibei,r2_qc_yibei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more relaxed filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717 w/ any fmriprepped data (209 ASD, 127 NT)\n",
      "----Site RU: 86 ASD, 76 NT\n",
      "----Site CUNY: 20 ASD, 7 NT\n",
      "----Site CBIC: 103 ASD, 44 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 189 ASD, 120 NT\n",
      "646 w/ all 4 runs (75 ASD, 42 NT )\n",
      "----Site RU: 28 ASD, 26 NT\n",
      "----Site CUNY: 9 ASD, 1 NT\n",
      "----Site CBIC: 38 ASD, 15 NT\n",
      "----Site SI: a group has 0\n",
      "----Site RU+CBIC: 66 ASD, 41 NT\n",
      "1160 w/ at least DM (141 ASD, 90 NT )\n",
      "----Site RU+CBIC: 126 ASD, 85 NT\n",
      "876 w/ at least DM and 1 resting state (103 ASD, 53 NT )\n",
      "----Site RU+CBIC: 89 ASD, 52 NT\n",
      "739 w/ at least DM and both resting state (84 ASD, 46 NT )\n",
      "----Site RU+CBIC: 72 ASD, 45 NT\n"
     ]
    }
   ],
   "source": [
    "def relaxed_filter(df_in):\n",
    "    #If the number of timepoints with a mean FD > 0.2mm is greater than 40% per individual the subject will be excluded \n",
    "    dm1 = df_in[df_in['fd_perc'] < 50]\n",
    "    \n",
    "    # dm_mean_tsnr = df_in['tsnr'].mean()\n",
    "    # dm2 = dm1[dm1['tsnr'] > dm_mean_tsnr]\n",
    "    return dm1\n",
    "\n",
    "dm_qc_relaxed=relaxed_filter(dm_qc)\n",
    "tp_qc_relaxed=relaxed_filter(tp_qc)\n",
    "r1_qc_relaxed=relaxed_filter(r1_qc)\n",
    "r2_qc_relaxed=relaxed_filter(r2_qc)\n",
    "\n",
    "anyruns,allruns=count_subjects(dm_qc_relaxed,\n",
    "                               tp_qc_relaxed,\n",
    "                               r1_qc_relaxed,\n",
    "                               r2_qc_relaxed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dm_qc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FD: 0.520 mm\n",
      "\n",
      "Mean TSNR: 27.542\n",
      "\n",
      "Mean SNR: 2.810\n",
      "\n",
      "Mean DVARS: 1.049\n",
      "\n",
      "Mean GCOR: 0.030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean FD: {dm_qc['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {dm_qc['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {dm_qc['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {dm_qc['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {dm_qc['gcor'].mean():.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framewise Displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filer out fd_perc > fd_perc.mean (group mean)\n",
    "\n",
    "`fd_perc`: the percent of FDs above the FD threshold (0.2) w.r.t. the full timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.143411626439025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_qc['fd_perc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 subjects have FD (0.2) percentage < 48.14 %\n"
     ]
    }
   ],
   "source": [
    "dm_mean_fd_perc = dm_qc['fd_perc'].mean()\n",
    "dm1 = dm_qc[dm_qc['fd_perc'] < dm_mean_fd_perc]\n",
    "print(f\"{dm1.shape[0]} subjects have FD (0.2) percentage < {dm_mean_fd_perc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aor</th>\n",
       "      <th>aqi</th>\n",
       "      <th>dvars_nstd</th>\n",
       "      <th>dvars_std</th>\n",
       "      <th>dvars_vstd</th>\n",
       "      <th>efc</th>\n",
       "      <th>fber</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_num</th>\n",
       "      <th>fd_perc</th>\n",
       "      <th>fwhm_avg</th>\n",
       "      <th>gcor</th>\n",
       "      <th>gsr_x</th>\n",
       "      <th>gsr_y</th>\n",
       "      <th>snr</th>\n",
       "      <th>spacing_tr</th>\n",
       "      <th>tsnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>38.235329</td>\n",
       "      <td>1.048682</td>\n",
       "      <td>0.995655</td>\n",
       "      <td>0.519457</td>\n",
       "      <td>1128.952728</td>\n",
       "      <td>0.211388</td>\n",
       "      <td>191.556364</td>\n",
       "      <td>25.743552</td>\n",
       "      <td>2.727841</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>0.054006</td>\n",
       "      <td>2.781134</td>\n",
       "      <td>0.8</td>\n",
       "      <td>31.983472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>13.312118</td>\n",
       "      <td>0.058479</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>0.029472</td>\n",
       "      <td>459.126789</td>\n",
       "      <td>0.124288</td>\n",
       "      <td>105.733159</td>\n",
       "      <td>14.045017</td>\n",
       "      <td>0.246584</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.021066</td>\n",
       "      <td>0.448340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.494614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>24.727956</td>\n",
       "      <td>0.853514</td>\n",
       "      <td>0.873382</td>\n",
       "      <td>0.427141</td>\n",
       "      <td>1.230067</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220265</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.043818</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>0.667309</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.901852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>33.929247</td>\n",
       "      <td>1.014497</td>\n",
       "      <td>0.973798</td>\n",
       "      <td>0.500520</td>\n",
       "      <td>802.881653</td>\n",
       "      <td>0.142627</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>13.713655</td>\n",
       "      <td>2.571328</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>-0.013414</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>2.464801</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27.842448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>37.263861</td>\n",
       "      <td>1.044189</td>\n",
       "      <td>0.992736</td>\n",
       "      <td>0.517894</td>\n",
       "      <td>1031.800781</td>\n",
       "      <td>0.180028</td>\n",
       "      <td>198.500000</td>\n",
       "      <td>26.835781</td>\n",
       "      <td>2.693636</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>-0.008757</td>\n",
       "      <td>0.050212</td>\n",
       "      <td>2.744420</td>\n",
       "      <td>0.8</td>\n",
       "      <td>31.775132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>40.997258</td>\n",
       "      <td>1.076858</td>\n",
       "      <td>1.007397</td>\n",
       "      <td>0.537296</td>\n",
       "      <td>1443.624512</td>\n",
       "      <td>0.238163</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>38.197008</td>\n",
       "      <td>2.826035</td>\n",
       "      <td>0.029655</td>\n",
       "      <td>-0.002803</td>\n",
       "      <td>0.065044</td>\n",
       "      <td>3.055000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>36.381478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.042380</td>\n",
       "      <td>0.170208</td>\n",
       "      <td>434.711937</td>\n",
       "      <td>1.503427</td>\n",
       "      <td>3.634369</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>2501.226807</td>\n",
       "      <td>1.456239</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>48.133333</td>\n",
       "      <td>4.930612</td>\n",
       "      <td>0.356133</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>0.276755</td>\n",
       "      <td>4.166971</td>\n",
       "      <td>0.8</td>\n",
       "      <td>67.465315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               aor          aqi   dvars_nstd    dvars_std   dvars_vstd  \\\n",
       "count  1100.000000  1100.000000  1100.000000  1100.000000  1100.000000   \n",
       "mean      0.002380     0.012340    38.235329     1.048682     0.995655   \n",
       "std       0.003372     0.008411    13.312118     0.058479     0.088439   \n",
       "min       0.000138     0.001913    24.727956     0.853514     0.873382   \n",
       "25%       0.000737     0.007696    33.929247     1.014497     0.973798   \n",
       "50%       0.001427     0.010844    37.263861     1.044189     0.992736   \n",
       "75%       0.002676     0.014387    40.997258     1.076858     1.007397   \n",
       "max       0.042380     0.170208   434.711937     1.503427     3.634369   \n",
       "\n",
       "               efc         fber      fd_mean       fd_num      fd_perc  \\\n",
       "count  1100.000000  1100.000000  1100.000000  1100.000000  1100.000000   \n",
       "mean      0.519457  1128.952728     0.211388   191.556364    25.743552   \n",
       "std       0.029472   459.126789     0.124288   105.733159    14.045017   \n",
       "min       0.427141     1.230067     0.053045     0.000000     0.000000   \n",
       "25%       0.500520   802.881653     0.142627   101.000000    13.713655   \n",
       "50%       0.517894  1031.800781     0.180028   198.500000    26.835781   \n",
       "75%       0.537296  1443.624512     0.238163   286.000000    38.197008   \n",
       "max       0.763758  2501.226807     1.456239   361.000000    48.133333   \n",
       "\n",
       "          fwhm_avg         gcor        gsr_x        gsr_y          snr  \\\n",
       "count  1100.000000  1100.000000  1100.000000  1100.000000  1100.000000   \n",
       "mean      2.727841     0.022130    -0.007437     0.054006     2.781134   \n",
       "std       0.246584     0.023694     0.009149     0.021066     0.448340   \n",
       "min       2.220265     0.000190    -0.043818     0.009750     0.667309   \n",
       "25%       2.571328     0.008441    -0.013414     0.039669     2.464801   \n",
       "50%       2.693636     0.015014    -0.008757     0.050212     2.744420   \n",
       "75%       2.826035     0.029655    -0.002803     0.065044     3.055000   \n",
       "max       4.930612     0.356133     0.033189     0.276755     4.166971   \n",
       "\n",
       "       spacing_tr         tsnr  \n",
       "count      1100.0  1100.000000  \n",
       "mean          0.8    31.983472  \n",
       "std           0.0     6.494614  \n",
       "min           0.8     7.901852  \n",
       "25%           0.8    27.842448  \n",
       "50%           0.8    31.775132  \n",
       "75%           0.8    36.381478  \n",
       "max           0.8    67.465315  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the first round of FD (0.2) percentage filtering:\n",
      "\n",
      "Mean FD: 0.211 mm\n",
      "\n",
      "Mean TSNR: 31.983\n",
      "\n",
      "Mean SNR: 2.781\n",
      "\n",
      "Mean DVARS: 1.049\n",
      "\n",
      "Mean GCOR: 0.022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After the first round of FD (0.2) percentage filtering:\\n\")\n",
    "print(f\"Mean FD: {dm1['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {dm1['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {dm1['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {dm1['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {dm1['gcor'].mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out low temporal SNR\n",
    "\n",
    "We notice that the minimal value of `tsnr` in `dm1` is 7.901852, which is too low\n",
    "\n",
    "We are going to use the group (before any filteration) mean tsnr as the threshold for filteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837 subjects have TSNR > 27.54\n"
     ]
    }
   ],
   "source": [
    "dm_mean_tsnr = dm_qc['tsnr'].mean()\n",
    "dm2 = dm1[dm1['tsnr'] > dm_mean_tsnr]\n",
    "print(f\"{dm2.shape[0]} subjects have TSNR > {dm_mean_tsnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aor</th>\n",
       "      <th>aqi</th>\n",
       "      <th>dvars_nstd</th>\n",
       "      <th>dvars_std</th>\n",
       "      <th>dvars_vstd</th>\n",
       "      <th>efc</th>\n",
       "      <th>fber</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_num</th>\n",
       "      <th>fd_perc</th>\n",
       "      <th>fwhm_avg</th>\n",
       "      <th>gcor</th>\n",
       "      <th>gsr_x</th>\n",
       "      <th>gsr_y</th>\n",
       "      <th>snr</th>\n",
       "      <th>spacing_tr</th>\n",
       "      <th>tsnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>837.0</td>\n",
       "      <td>837.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>35.984161</td>\n",
       "      <td>1.058905</td>\n",
       "      <td>1.000350</td>\n",
       "      <td>0.517322</td>\n",
       "      <td>1178.807498</td>\n",
       "      <td>0.170055</td>\n",
       "      <td>171.428913</td>\n",
       "      <td>23.104405</td>\n",
       "      <td>2.714004</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>0.053157</td>\n",
       "      <td>2.800862</td>\n",
       "      <td>0.8</td>\n",
       "      <td>34.625673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>4.215710</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.027955</td>\n",
       "      <td>464.038300</td>\n",
       "      <td>0.056830</td>\n",
       "      <td>105.110838</td>\n",
       "      <td>13.977248</td>\n",
       "      <td>0.236348</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.786316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>24.727956</td>\n",
       "      <td>0.939437</td>\n",
       "      <td>0.921666</td>\n",
       "      <td>0.427141</td>\n",
       "      <td>283.035400</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220265</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>-0.034041</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>1.683540</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27.551781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>32.879999</td>\n",
       "      <td>1.024534</td>\n",
       "      <td>0.980766</td>\n",
       "      <td>0.499761</td>\n",
       "      <td>840.146057</td>\n",
       "      <td>0.131676</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11.081442</td>\n",
       "      <td>2.560565</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.038949</td>\n",
       "      <td>2.473086</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.842398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>35.919805</td>\n",
       "      <td>1.051980</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>0.515304</td>\n",
       "      <td>1078.717651</td>\n",
       "      <td>0.162410</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>22.994652</td>\n",
       "      <td>2.675829</td>\n",
       "      <td>0.014814</td>\n",
       "      <td>-0.009344</td>\n",
       "      <td>0.049216</td>\n",
       "      <td>2.753416</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33.891055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>38.676866</td>\n",
       "      <td>1.084067</td>\n",
       "      <td>1.008828</td>\n",
       "      <td>0.534505</td>\n",
       "      <td>1532.001953</td>\n",
       "      <td>0.196906</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>34.491979</td>\n",
       "      <td>2.815848</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>-0.003563</td>\n",
       "      <td>0.064736</td>\n",
       "      <td>3.085826</td>\n",
       "      <td>0.8</td>\n",
       "      <td>37.489911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.042380</td>\n",
       "      <td>0.023108</td>\n",
       "      <td>52.098724</td>\n",
       "      <td>1.503427</td>\n",
       "      <td>3.634369</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>2501.226807</td>\n",
       "      <td>0.415858</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>48.133333</td>\n",
       "      <td>3.812912</td>\n",
       "      <td>0.193301</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>4.166971</td>\n",
       "      <td>0.8</td>\n",
       "      <td>67.465315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              aor         aqi  dvars_nstd   dvars_std  dvars_vstd         efc  \\\n",
       "count  837.000000  837.000000  837.000000  837.000000  837.000000  837.000000   \n",
       "mean     0.001694    0.009505   35.984161    1.058905    1.000350    0.517322   \n",
       "std      0.002526    0.003076    4.215710    0.052945    0.097025    0.027955   \n",
       "min      0.000138    0.001913   24.727956    0.939437    0.921666    0.427141   \n",
       "25%      0.000631    0.007023   32.879999    1.024534    0.980766    0.499761   \n",
       "50%      0.001126    0.009377   35.919805    1.051980    0.995718    0.515304   \n",
       "75%      0.001952    0.011599   38.676866    1.084067    1.008828    0.534505   \n",
       "max      0.042380    0.023108   52.098724    1.503427    3.634369    0.602229   \n",
       "\n",
       "              fber     fd_mean      fd_num     fd_perc    fwhm_avg  \\\n",
       "count   837.000000  837.000000  837.000000  837.000000  837.000000   \n",
       "mean   1178.807498    0.170055  171.428913   23.104405    2.714004   \n",
       "std     464.038300    0.056830  105.110838   13.977248    0.236348   \n",
       "min     283.035400    0.053045    0.000000    0.000000    2.220265   \n",
       "25%     840.146057    0.131676   80.000000   11.081442    2.560565   \n",
       "50%    1078.717651    0.162410  170.000000   22.994652    2.675829   \n",
       "75%    1532.001953    0.196906  258.000000   34.491979    2.815848   \n",
       "max    2501.226807    0.415858  361.000000   48.133333    3.812912   \n",
       "\n",
       "             gcor       gsr_x       gsr_y         snr  spacing_tr        tsnr  \n",
       "count  837.000000  837.000000  837.000000  837.000000       837.0  837.000000  \n",
       "mean     0.021152   -0.007985    0.053157    2.800862         0.8   34.625673  \n",
       "std      0.019067    0.008850    0.019952    0.451600         0.0    4.786316  \n",
       "min      0.001729   -0.034041    0.009750    1.683540         0.8   27.551781  \n",
       "25%      0.008319   -0.013694    0.038949    2.473086         0.8   30.842398  \n",
       "50%      0.014814   -0.009344    0.049216    2.753416         0.8   33.891055  \n",
       "75%      0.029523   -0.003563    0.064736    3.085826         0.8   37.489911  \n",
       "max      0.193301    0.033189    0.155104    4.166971         0.8   67.465315  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the second round of tSNR filtering:\n",
      "\n",
      "Mean FD: 0.170 mm\n",
      "\n",
      "Mean TSNR: 34.626\n",
      "\n",
      "Mean SNR: 2.801\n",
      "\n",
      "Mean DVARS: 1.059\n",
      "\n",
      "Mean GCOR: 0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After the second round of tSNR filtering:\\n\")\n",
    "print(f\"Mean FD: {dm2['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {dm2['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {dm2['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {dm2['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {dm2['gcor'].mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of other metrics did not change much after those two steps; we can stop now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save subject list based on the QC\n",
    "df1 = movieDM_qc[movieDM_qc['fd_perc'] < dm_mean_fd_perc]\n",
    "df2 = df1[df1['tsnr'] > dm_mean_tsnr]\n",
    "dm_subj_list = df2['subj_id'].tolist()\n",
    "dm_subj_list.sort()\n",
    "np.savetxt(os.path.join(save_dir, \"movieDM_qc_subj_list.txt\"), dm_subj_list, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_qc = movieTP_qc[iqms].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aor</th>\n",
       "      <th>aqi</th>\n",
       "      <th>dvars_nstd</th>\n",
       "      <th>dvars_std</th>\n",
       "      <th>dvars_vstd</th>\n",
       "      <th>efc</th>\n",
       "      <th>fber</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_num</th>\n",
       "      <th>fd_perc</th>\n",
       "      <th>fwhm_avg</th>\n",
       "      <th>gcor</th>\n",
       "      <th>gsr_x</th>\n",
       "      <th>gsr_y</th>\n",
       "      <th>snr</th>\n",
       "      <th>spacing_tr</th>\n",
       "      <th>tsnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.000000</td>\n",
       "      <td>2325.0</td>\n",
       "      <td>2325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.015754</td>\n",
       "      <td>43.734812</td>\n",
       "      <td>1.072434</td>\n",
       "      <td>1.021051</td>\n",
       "      <td>0.512416</td>\n",
       "      <td>1187.414519</td>\n",
       "      <td>0.451427</td>\n",
       "      <td>110.986237</td>\n",
       "      <td>44.908167</td>\n",
       "      <td>2.781288</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>0.052724</td>\n",
       "      <td>2.805682</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.752406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.017068</td>\n",
       "      <td>16.487683</td>\n",
       "      <td>0.071512</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>450.156058</td>\n",
       "      <td>0.928457</td>\n",
       "      <td>63.946095</td>\n",
       "      <td>25.665328</td>\n",
       "      <td>0.298794</td>\n",
       "      <td>0.036311</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>0.497371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.292436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>24.850039</td>\n",
       "      <td>0.733935</td>\n",
       "      <td>0.749377</td>\n",
       "      <td>0.371932</td>\n",
       "      <td>187.115463</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.123325</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>-0.033902</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>1.385142</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.823612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>35.606258</td>\n",
       "      <td>1.031807</td>\n",
       "      <td>0.990841</td>\n",
       "      <td>0.493570</td>\n",
       "      <td>869.075928</td>\n",
       "      <td>0.172736</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>24.193548</td>\n",
       "      <td>2.578154</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>-0.011130</td>\n",
       "      <td>0.039003</td>\n",
       "      <td>2.427492</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.245385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003579</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>39.910123</td>\n",
       "      <td>1.065827</td>\n",
       "      <td>1.009702</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>1094.060913</td>\n",
       "      <td>0.259644</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>2.733339</td>\n",
       "      <td>0.012518</td>\n",
       "      <td>-0.005450</td>\n",
       "      <td>0.049857</td>\n",
       "      <td>2.727000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>31.004788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>46.602137</td>\n",
       "      <td>1.106186</td>\n",
       "      <td>1.034873</td>\n",
       "      <td>0.531815</td>\n",
       "      <td>1491.928101</td>\n",
       "      <td>0.463297</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>65.587045</td>\n",
       "      <td>2.942952</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.063579</td>\n",
       "      <td>3.146200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>36.637471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.112813</td>\n",
       "      <td>0.251635</td>\n",
       "      <td>316.693373</td>\n",
       "      <td>1.656432</td>\n",
       "      <td>2.088032</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>2503.713623</td>\n",
       "      <td>24.615591</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>99.600000</td>\n",
       "      <td>5.661200</td>\n",
       "      <td>0.735693</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>4.539780</td>\n",
       "      <td>0.8</td>\n",
       "      <td>52.055197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               aor          aqi   dvars_nstd    dvars_std   dvars_vstd  \\\n",
       "count  2325.000000  2325.000000  2325.000000  2325.000000  2325.000000   \n",
       "mean      0.006162     0.015754    43.734812     1.072434     1.021051   \n",
       "std       0.008024     0.017068    16.487683     0.071512     0.066396   \n",
       "min       0.000350     0.002544    24.850039     0.733935     0.749377   \n",
       "25%       0.001623     0.007660    35.606258     1.031807     0.990841   \n",
       "50%       0.003579     0.011412    39.910123     1.065827     1.009702   \n",
       "75%       0.007597     0.017825    46.602137     1.106186     1.034873   \n",
       "max       0.112813     0.251635   316.693373     1.656432     2.088032   \n",
       "\n",
       "               efc         fber      fd_mean       fd_num      fd_perc  \\\n",
       "count  2325.000000  2325.000000  2325.000000  2325.000000  2325.000000   \n",
       "mean      0.512416  1187.414519     0.451427   110.986237    44.908167   \n",
       "std       0.029891   450.156058     0.928457    63.946095    25.665328   \n",
       "min       0.371932   187.115463     0.050811     0.000000     0.000000   \n",
       "25%       0.493570   869.075928     0.172736    59.000000    24.193548   \n",
       "50%       0.512508  1094.060913     0.259644   112.000000    45.600000   \n",
       "75%       0.531815  1491.928101     0.463297   162.000000    65.587045   \n",
       "max       0.613964  2503.713623    24.615591   249.000000    99.600000   \n",
       "\n",
       "          fwhm_avg         gcor        gsr_x        gsr_y          snr  \\\n",
       "count  2325.000000  2325.000000  2325.000000  2325.000000  2325.000000   \n",
       "mean      2.781288     0.021142    -0.004140     0.052724     2.805682   \n",
       "std       0.298794     0.036311     0.009878     0.019442     0.497371   \n",
       "min       2.123325     0.001509    -0.033902     0.010135     1.385142   \n",
       "25%       2.578154     0.007338    -0.011130     0.039003     2.427492   \n",
       "50%       2.733339     0.012518    -0.005450     0.049857     2.727000   \n",
       "75%       2.942952     0.022162     0.001734     0.063579     3.146200   \n",
       "max       5.661200     0.735693     0.036096     0.182667     4.539780   \n",
       "\n",
       "       spacing_tr         tsnr  \n",
       "count      2325.0  2325.000000  \n",
       "mean          0.8    30.752406  \n",
       "std           0.0     8.292436  \n",
       "min           0.8     2.823612  \n",
       "25%           0.8    25.245385  \n",
       "50%           0.8    31.004788  \n",
       "75%           0.8    36.637471  \n",
       "max           0.8    52.055197  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_qc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FD: 0.451 mm\n",
      "\n",
      "Mean TSNR: 30.752\n",
      "\n",
      "Mean SNR: 2.806\n",
      "\n",
      "Mean DVARS: 1.072\n",
      "\n",
      "Mean GCOR: 0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean FD: {tp_qc['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {tp_qc['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {tp_qc['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {tp_qc['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {tp_qc['gcor'].mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framewise Displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filer out fd_perc > fd_perc.mean (group mean)\n",
    "\n",
    "`fd_perc`: the percent of FDs above the FD threshold (0.2) w.r.t. the full timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145 subjects have FD (0.2) percentage < 44.91 %\n"
     ]
    }
   ],
   "source": [
    "tp_mean_fd_perc = tp_qc['fd_perc'].mean()\n",
    "tp1 = tp_qc[tp_qc['fd_perc'] < tp_mean_fd_perc]\n",
    "print(f\"{tp1.shape[0]} subjects have FD (0.2) percentage < {tp_mean_fd_perc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp_qc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtp_qc\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfd_perc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tp_qc' is not defined"
     ]
    }
   ],
   "source": [
    "tp_qc['fd_perc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aor</th>\n",
       "      <th>aqi</th>\n",
       "      <th>dvars_nstd</th>\n",
       "      <th>dvars_std</th>\n",
       "      <th>dvars_vstd</th>\n",
       "      <th>efc</th>\n",
       "      <th>fber</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_num</th>\n",
       "      <th>fd_perc</th>\n",
       "      <th>fwhm_avg</th>\n",
       "      <th>gcor</th>\n",
       "      <th>gsr_x</th>\n",
       "      <th>gsr_y</th>\n",
       "      <th>snr</th>\n",
       "      <th>spacing_tr</th>\n",
       "      <th>tsnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>37.116737</td>\n",
       "      <td>1.068534</td>\n",
       "      <td>1.018598</td>\n",
       "      <td>0.518321</td>\n",
       "      <td>1133.015994</td>\n",
       "      <td>0.196509</td>\n",
       "      <td>56.693450</td>\n",
       "      <td>22.826130</td>\n",
       "      <td>2.720349</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>-0.005445</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>2.783612</td>\n",
       "      <td>0.8</td>\n",
       "      <td>35.019498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>5.340744</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>0.047117</td>\n",
       "      <td>0.028893</td>\n",
       "      <td>450.497363</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>34.004851</td>\n",
       "      <td>13.687200</td>\n",
       "      <td>0.245165</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.020294</td>\n",
       "      <td>0.463018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.539626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>24.850039</td>\n",
       "      <td>0.824386</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>0.416752</td>\n",
       "      <td>240.785202</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.123325</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>-0.033902</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>1.385142</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16.262957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>33.467628</td>\n",
       "      <td>1.032207</td>\n",
       "      <td>0.994764</td>\n",
       "      <td>0.498882</td>\n",
       "      <td>818.192932</td>\n",
       "      <td>0.134590</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10.441767</td>\n",
       "      <td>2.558625</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>-0.012132</td>\n",
       "      <td>0.040381</td>\n",
       "      <td>2.440202</td>\n",
       "      <td>0.8</td>\n",
       "      <td>30.552039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>36.613770</td>\n",
       "      <td>1.062215</td>\n",
       "      <td>1.009705</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>1040.464355</td>\n",
       "      <td>0.171945</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>23.790323</td>\n",
       "      <td>2.682257</td>\n",
       "      <td>0.010735</td>\n",
       "      <td>-0.007038</td>\n",
       "      <td>0.051254</td>\n",
       "      <td>2.711634</td>\n",
       "      <td>0.8</td>\n",
       "      <td>34.915924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>40.077716</td>\n",
       "      <td>1.098756</td>\n",
       "      <td>1.031341</td>\n",
       "      <td>0.536627</td>\n",
       "      <td>1412.512451</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>35.222672</td>\n",
       "      <td>2.852565</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.066148</td>\n",
       "      <td>3.066438</td>\n",
       "      <td>0.8</td>\n",
       "      <td>39.595498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.046446</td>\n",
       "      <td>0.047857</td>\n",
       "      <td>67.744234</td>\n",
       "      <td>1.383352</td>\n",
       "      <td>1.378157</td>\n",
       "      <td>0.604693</td>\n",
       "      <td>2478.370117</td>\n",
       "      <td>1.191813</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>44.897959</td>\n",
       "      <td>4.478995</td>\n",
       "      <td>0.175595</td>\n",
       "      <td>0.036096</td>\n",
       "      <td>0.182667</td>\n",
       "      <td>4.253409</td>\n",
       "      <td>0.8</td>\n",
       "      <td>52.055197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               aor          aqi   dvars_nstd    dvars_std   dvars_vstd  \\\n",
       "count  1145.000000  1145.000000  1145.000000  1145.000000  1145.000000   \n",
       "mean      0.004068     0.009696    37.116737     1.068534     1.018598   \n",
       "std       0.004923     0.005062     5.340744     0.061882     0.047117   \n",
       "min       0.000350     0.002544    24.850039     0.824386     0.877493   \n",
       "25%       0.001121     0.006153    33.467628     1.032207     0.994764   \n",
       "50%       0.002295     0.008597    36.613770     1.062215     1.009705   \n",
       "75%       0.004798     0.011824    40.077716     1.098756     1.031341   \n",
       "max       0.046446     0.047857    67.744234     1.383352     1.378157   \n",
       "\n",
       "               efc         fber      fd_mean       fd_num      fd_perc  \\\n",
       "count  1145.000000  1145.000000  1145.000000  1145.000000  1145.000000   \n",
       "mean      0.518321  1133.015994     0.196509    56.693450    22.826130   \n",
       "std       0.028893   450.497363     0.111150    34.004851    13.687200   \n",
       "min       0.416752   240.785202     0.050811     0.000000     0.000000   \n",
       "25%       0.498882   818.192932     0.134590    26.000000    10.441767   \n",
       "50%       0.517565  1040.464355     0.171945    59.000000    23.790323   \n",
       "75%       0.536627  1412.512451     0.220401    88.000000    35.222672   \n",
       "max       0.604693  2478.370117     1.191813   112.000000    44.897959   \n",
       "\n",
       "          fwhm_avg         gcor        gsr_x        gsr_y          snr  \\\n",
       "count  1145.000000  1145.000000  1145.000000  1145.000000  1145.000000   \n",
       "mean      2.720349     0.014591    -0.005445     0.054412     2.783612   \n",
       "std       0.245165     0.014196     0.009705     0.020294     0.463018   \n",
       "min       2.123325     0.001703    -0.033902     0.010135     1.385142   \n",
       "25%       2.558625     0.006647    -0.012132     0.040381     2.440202   \n",
       "50%       2.682257     0.010735    -0.007038     0.051254     2.711634   \n",
       "75%       2.852565     0.017212    -0.000088     0.066148     3.066438   \n",
       "max       4.478995     0.175595     0.036096     0.182667     4.253409   \n",
       "\n",
       "       spacing_tr         tsnr  \n",
       "count      1145.0  1145.000000  \n",
       "mean          0.8    35.019498  \n",
       "std           0.0     6.539626  \n",
       "min           0.8    16.262957  \n",
       "25%           0.8    30.552039  \n",
       "50%           0.8    34.915924  \n",
       "75%           0.8    39.595498  \n",
       "max           0.8    52.055197  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the first round of FD (0.2) percentage filtering:\n",
      "\n",
      "Mean FD: 0.197 mm\n",
      "\n",
      "Mean TSNR: 35.019\n",
      "\n",
      "Mean SNR: 2.784\n",
      "\n",
      "Mean DVARS: 1.069\n",
      "\n",
      "Mean GCOR: 0.015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After the first round of FD (0.2) percentage filtering:\\n\")\n",
    "print(f\"Mean FD: {tp1['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {tp1['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {tp1['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {tp1['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {tp1['gcor'].mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out low temporal SNR\n",
    "\n",
    "We notice that the minimal value of `tsnr` in `dm2` is 6.539626, which is too low\n",
    "\n",
    "We are going to use the group (before any filteration) mean tsnr as the threshold for filteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845 subjects have TSNR > 30.75\n"
     ]
    }
   ],
   "source": [
    "tp_mean_tsnr = tp_qc['tsnr'].mean()\n",
    "tp2 = tp1[tp1['tsnr'] > tp_mean_tsnr]\n",
    "print(f\"{tp2.shape[0]} subjects have TSNR > {tp_mean_tsnr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the second round of tSNR filtering:\n",
      "\n",
      "Mean FD: 0.159 mm\n",
      "\n",
      "Mean TSNR: 37.914\n",
      "\n",
      "Mean SNR: 2.829\n",
      "\n",
      "Mean DVARS: 1.073\n",
      "\n",
      "Mean GCOR: 0.013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After the second round of tSNR filtering:\\n\")\n",
    "print(f\"Mean FD: {tp2['fd_mean'].mean():.3f} mm\\n\")\n",
    "print(f\"Mean TSNR: {tp2['tsnr'].mean():.3f}\\n\")\n",
    "print(f\"Mean SNR: {tp2['snr'].mean():.3f}\\n\")\n",
    "print(f\"Mean DVARS: {tp2['dvars_std'].mean():.3f}\\n\")\n",
    "print(f\"Mean GCOR: {tp2['gcor'].mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of other metrics did not change much after those two steps; we can stop now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save subject list based on the QC\n",
    "df1 = movieTP_qc[movieTP_qc['fd_perc'] < tp_mean_fd_perc]\n",
    "df2 = df1[df1['tsnr'] > tp_mean_tsnr]\n",
    "tp_subj_list = df2['subj_id'].tolist()\n",
    "tp_subj_list.sort()\n",
    "np.savetxt(os.path.join(save_dir, \"movieTP_qc_subj_list.txt\"), tp_subj_list, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 subjects are common between movieDM and movieTP\n"
     ]
    }
   ],
   "source": [
    "dm_subj_list = set(dm_subj_list)\n",
    "tp_subj_list = set(tp_subj_list)\n",
    "common_subj_list = list(dm_subj_list.intersection(tp_subj_list))\n",
    "common_subj_list.sort()\n",
    "print(f\"{len(common_subj_list)} subjects are common between movieDM and movieTP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
