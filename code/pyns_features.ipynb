{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animated-sculpture",
   "metadata": {},
   "source": [
    "# notebook to get all features from pliers and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "listed-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(\"paper\", \"white\")\n",
    "from pyns import Neuroscout\n",
    "import math\n",
    "\n",
    "api = Neuroscout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liquid-private",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset count = 13\n",
      "\n",
      "Datasets and IDs:\n",
      "\n",
      "HealthyBrainNetwork 8\n",
      "studyforrest 11\n",
      "Raiders 10\n",
      "SchematicNarrative 20\n",
      "SherlockMerlin 5\n",
      "Sherlock 21\n",
      "narratives 30\n",
      "Life 9\n",
      "ParanoiaStory 18\n",
      "LearningTemporalStructure 19\n",
      "Budapest 27\n",
      "NaturalisticNeuroimagingDatabase 28\n",
      "ReadingBrainProject 29\n"
     ]
    }
   ],
   "source": [
    "datasets = api.datasets.get()\n",
    "print(f'dataset count = {len(api.datasets.get())}\\n')\n",
    "print('Datasets and IDs:\\n')\n",
    "for i in datasets:\n",
    "    print(i['name'], i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smaller-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParanoiStory (audio only) LearningTemporalStructure and ReadingBrainProject should be excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-lawsuit",
   "metadata": {},
   "source": [
    "#### get the id of a subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sufficient-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = api.runs.get(dataset_id=8)[0]['subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-crest",
   "metadata": {},
   "source": [
    "### let's just look at budapest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boxed-athens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acquisition': None,\n",
       "  'dataset_id': 8,\n",
       "  'duration': 600.0000089406967,\n",
       "  'id': 211,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': 'NDARYX592YYR',\n",
       "  'task': 7,\n",
       "  'task_name': 'movieDM'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.runs.get(dataset_id=8, subject=subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "encouraging-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the run number for just HBN, NDARYX592YYR, 7\n",
    "run_id=api.runs.get(dataset_id=8, subject=subject)[0]['id']\n",
    "run_duration=api.runs.get(dataset_id=8, subject=subject)[0]['duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-quest",
   "metadata": {},
   "source": [
    "### get just the non-fmriprep predictors and those that have a calculated mean (floats, ints, binary, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(run_id):\n",
    "    # input: a neuroscout run_id \n",
    "    # outputs:\n",
    "    # - a pandas dataframe of predictors\n",
    "    # - list of ids\n",
    "    # - list of names\n",
    "    # - list of modality\n",
    "    predictors=api.predictors.get(run_id=run_id)\n",
    "    predictor_ids = []\n",
    "    predictor_names = []\n",
    "    predictor_modality = []\n",
    "    for i in predictors:\n",
    "        if not i['source'] == 'fmriprep' and not i['mean'] == None and str(i['name']).find(\"bert\") < 0:\n",
    "            predictor_ids.append(i['id'])\n",
    "            predictor_names.append(i['name'])\n",
    "            try:\n",
    "                predictor_modality.append(i['extracted_feature']['modality'])\n",
    "            except:\n",
    "                predictor_modality.append(None)\n",
    "                \n",
    "    df_predictors=pd.DataFrame(data= np.array([predictor_ids,predictor_modality,predictor_names]).T , columns=['id','modality','names'])\n",
    "    df_predictors = df_predictors.sort_values(by=['id','names','modality'])\n",
    "    predictor_ids= df_predictors['id'].to_numpy()\n",
    "    predictor_names= df_predictors['names'].to_numpy()\n",
    "    predictor_modality= df_predictors['modality'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "    return(df_predictors, predictor_ids, predictor_names, predictor_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "behind-saturday",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-30356915dfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_predictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor_modality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_id' is not defined"
     ]
    }
   ],
   "source": [
    "df_predictors, predictor_ids, predictor_names, predictor_modality = get_predictors(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-glory",
   "metadata": {},
   "source": [
    "### load into pandas df, sort predictors by id, name, modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-macedonia",
   "metadata": {},
   "source": [
    "#### how many values are in each predictor??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-layout",
   "metadata": {},
   "source": [
    "load an event into df, sort it by onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outstanding-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries(predictor_ids,run_id,run_duration):\n",
    "    # input: list of predictor IDs\n",
    "    # output: an array of predictors as 1 hz timeseries\n",
    "    #\n",
    "    ### given an event... convert it from duration onset value to timeseries\n",
    "    # - sort it (the dicts are out of order)\n",
    "    # - convert to timeseries\n",
    "    # - resample it to 1 hz now as a start\n",
    "    all_feats = []\n",
    "    for pred_id in predictor_ids:\n",
    "        an_event=api.predictor_events.get(predictor_id=pred_id,run_id=run_id,stimulus_timing=True)\n",
    "        data = np.zeros((int(run_duration)))\n",
    "        for i in an_event:\n",
    "            start = round(i['onset'])\n",
    "            stop = start + math.ceil(i['duration'])\n",
    "            value = i['value']\n",
    "            #onset=round(onset)\n",
    "            try:\n",
    "                data[start:stop]=value\n",
    "            except:\n",
    "                #print()\n",
    "                print(f'skipped {value}')\n",
    "\n",
    "        all_feats.append(data)\n",
    "    all_feats = np.asarray(all_feats)\n",
    "    return(all_feats)\n",
    "    #all_feats is length = # predictors each predictor is size = run duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flying-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = get_timeseries(predictor_ids,run_id,run_duration)\n",
    "\n",
    "df = pd.DataFrame(data=all_feats.T,columns =predictor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "preliminary-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../sourcedata/data/HBN/features/DM_pliers_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-revision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
