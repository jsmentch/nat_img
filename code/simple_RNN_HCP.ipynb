{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make a very simple LSTM model with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how long this will take to run for 7t data with a not too complicated model and what kind of resources we are talking about - single run single subject.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import hrf_tools\n",
    "#from analysis import load_data_HCP_MMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_HCP_MMP(subject,feature,n_movies):\n",
    "    # Inputs: subject = HCP id eg 100610\n",
    "    #         feature='mfs'\n",
    "    #         n_movies is a list of movie indices 1 thru 4\n",
    "    # Returns: X feature data (2D; time x feature)\n",
    "    #          Y brain data (2D; time x grayordinate)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from scipy.signal import resample\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    y_l=[]\n",
    "    x_l=[]\n",
    "    stim = ['tfMRI_MOVIE1_7T_AP','tfMRI_MOVIE2_7T_PA','tfMRI_MOVIE3_7T_PA','tfMRI_MOVIE4_7T_AP']\n",
    "    stim_feat = ['7T_MOVIE1_CC1_v2', '7T_MOVIE2_HO1_v2', '7T_MOVIE3_CC2_v2', '7T_MOVIE4_HO2_v2']\n",
    "    slice_starts = [\n",
    "        [20,284, 526,734],\n",
    "        [20,267,545],\n",
    "        [20,221,425,649],\n",
    "        [20,272,522]]\n",
    "    slice_stops =  [\n",
    "        [264,506,714,798],\n",
    "        [247,525,795],\n",
    "        [201,405,629,792],\n",
    "        [252,502,777]]\n",
    "    for i in n_movies:\n",
    "        i=i-1\n",
    "        exclude_final=slice_stops[i][-1] #trim the final movie since it is in all scans\n",
    "        #load brain image\n",
    "        im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/parcellations/parcellated/sub{str(subject)}_{stim[i]}.ptseries.nii'\n",
    "        img = nb.load(im_file)\n",
    "        img_y = img.get_fdata()\n",
    "        img_y = scaler.fit_transform(img_y)\n",
    "\n",
    "        #load feature\n",
    "        feat_x = np.load(f'../sourcedata/data/HCP_7T_movie_FIX/features/{stim_feat[i]}_{feature}.npy')\n",
    "        feat_x = resample(feat_x, img_y.shape[0], axis=0) #resample to 1hz for now \n",
    "        #feat_x=feat_x.T\n",
    "        #trim final movies\n",
    "        img_y = img_y[:exclude_final,:]\n",
    "        feat_x = feat_x[:exclude_final,:]\n",
    "        y_l.append(img_y)\n",
    "        x_l.append(feat_x)\n",
    "    Y=np.vstack(y_l)\n",
    "    X=np.vstack(x_l)\n",
    "    #X = scaler.fit_transform(X)\n",
    "    #vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10957096950636860581\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23552872960\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1229633727219759524\n",
      "physical_device_desc: \"device: 0, name: Quadro RTX 6000, pci bus id: 0000:5e:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=100610\n",
    "feature='as_scores'\n",
    "n_movies=[1,2,3]\n",
    "X,Y = load_data_HCP_MMP(subject,feature,n_movies)\n",
    "\n",
    "X_test,Y_test = load_data_HCP_MMP(subject,feature,[4])\n",
    "\n",
    "X = hrf_tools.apply_optimal_hrf_10hz(X,1)\n",
    "X_test = hrf_tools.apply_optimal_hrf_10hz(X_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2385, 521)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X[:-500,:]\n",
    "Y_val = Y[:-500,:]\n",
    "X_train = X[-500:,:]\n",
    "Y_train = Y[-500:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 360)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[-500:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "time_steps = 10\n",
    "input_units = 521\n",
    "input_shape = (time_steps,input_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/preprocessing/timeseries/\n",
    "dataset_train = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_train, \n",
    "                                                     targets = Y_train, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)\n",
    "dataset_val = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_val, \n",
    "                                                     targets = Y_val, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)\n",
    "\n",
    "dataset_test = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_test, \n",
    "                                                     targets = Y_test, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### design a simple(?) lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_6 (Dropout)          (None, 10, 521)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 521)               2173612   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 521)               271962    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 521)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 521)               271962    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 521)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 360)               187920    \n",
      "=================================================================\n",
      "Total params: 2,905,456\n",
      "Trainable params: 2,905,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "#model.add(layers.Embedding(input_dim=1024, output_dim=1024))\n",
    "\n",
    "model.add(keras.Input(shape=input_shape)) #omit beacuse of bug\n",
    "model.add(layers.Dropout(0.1))\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(input_units))#,batch_input_shape=(batch_size, time_steps, input_units)))\n",
    "model.add(layers.Dense(521,activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(521,activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "#model.add(layers.Dense(360))\n",
    "\n",
    "#model.add(layers.UpSampling1D(size=10))\n",
    "#model.add(layers.Dense(17049))\n",
    "#model.add(layers.Dense(128))\n",
    "model.add(layers.Dense(360,activation='relu'))\n",
    "#model.add(layers.Dense(360))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(x_train,0), np.expand_dims(y_train,0)))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X_hrf, Y))\n",
    "\n",
    "# dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Buffer size to shuffle the dataset\n",
    "# # (TF data is designed to work with possibly infinite sequences,\n",
    "# # so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# # it maintains a buffer in which it shuffles elements).\n",
    "# BUFFER_SIZE = 10000\n",
    "\n",
    "# dataset = (\n",
    "#     dataset\n",
    "#     .shuffle(BUFFER_SIZE)\n",
    "#     .batch(batch_size, drop_remainder=True)\n",
    "#     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#simple_rnn = layers.SimpleRNN(18, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_sequence_output, final_state = simple_rnn(np.expand_dims(x_train,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, restore_best_weights=True, patience=25)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"),\n",
    "    optimizer=\"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.6114 - val_loss: 0.5919\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6119 - val_loss: 0.5903\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6133 - val_loss: 0.5958\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6126 - val_loss: 0.5966\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6146 - val_loss: 0.5937\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6108 - val_loss: 0.5945\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6165 - val_loss: 0.5909\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6127 - val_loss: 0.5865\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6106 - val_loss: 0.5899\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6135 - val_loss: 0.5912\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6117 - val_loss: 0.5889\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6112 - val_loss: 0.5896\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6095 - val_loss: 0.5891\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6088 - val_loss: 0.5846\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6098 - val_loss: 0.5889\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6100 - val_loss: 0.5934\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6194 - val_loss: 0.6030\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6162 - val_loss: 0.5883\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6111 - val_loss: 0.5924\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6082 - val_loss: 0.5914\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6106 - val_loss: 0.5929\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6132 - val_loss: 0.5909\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.6127 - val_loss: 0.5827\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6078 - val_loss: 0.5864\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6068 - val_loss: 0.5835\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6085 - val_loss: 0.5850\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6079 - val_loss: 0.5844\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6062 - val_loss: 0.5865\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6066 - val_loss: 0.5901\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6085 - val_loss: 0.5866\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6083 - val_loss: 0.5851\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6081 - val_loss: 0.5834\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6074 - val_loss: 0.5867\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6106 - val_loss: 0.5934\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6127 - val_loss: 0.5973\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6137 - val_loss: 0.5908\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6101 - val_loss: 0.5882\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6090 - val_loss: 0.5904\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6092 - val_loss: 0.5883\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6064 - val_loss: 0.5858\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6077 - val_loss: 0.5856\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6092 - val_loss: 0.5904\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6092 - val_loss: 0.5851\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6085 - val_loss: 0.5913\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6104 - val_loss: 0.5858\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6087 - val_loss: 0.5820\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6052 - val_loss: 0.5844\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6051 - val_loss: 0.5808\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6040 - val_loss: 0.5848\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6072 - val_loss: 0.5880\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6090 - val_loss: 0.5868\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6073 - val_loss: 0.5828\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6054 - val_loss: 0.5811\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6026 - val_loss: 0.5821\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6042 - val_loss: 0.5867\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6082 - val_loss: 0.5930\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6137 - val_loss: 0.5941\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6139 - val_loss: 0.5980\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6154 - val_loss: 0.5927\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6148 - val_loss: 0.5913\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6116 - val_loss: 0.5879\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6107 - val_loss: 0.5909\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6103 - val_loss: 0.5851\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6054 - val_loss: 0.5875\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6086 - val_loss: 0.5923\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6095 - val_loss: 0.5836\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6056 - val_loss: 0.5821\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6034 - val_loss: 0.5821\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6033 - val_loss: 0.5795\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6046 - val_loss: 0.5837\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6049 - val_loss: 0.5812\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6043 - val_loss: 0.5836\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6050 - val_loss: 0.5865\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6073 - val_loss: 0.5814\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6086 - val_loss: 0.5887\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6105 - val_loss: 0.5865\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6063 - val_loss: 0.5864\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6079 - val_loss: 0.5883\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6061 - val_loss: 0.5823\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6048 - val_loss: 0.5886\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6050 - val_loss: 0.5815\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6059 - val_loss: 0.5830\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6038 - val_loss: 0.5802\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6043 - val_loss: 0.5786\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6009 - val_loss: 0.5807\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6029 - val_loss: 0.5915\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6040 - val_loss: 0.5855\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6073 - val_loss: 0.5883\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6067 - val_loss: 0.5848\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6065 - val_loss: 0.5825\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6047 - val_loss: 0.5779\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.6041 - val_loss: 0.5807\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6053 - val_loss: 0.5848\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6079 - val_loss: 0.5833\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6048 - val_loss: 0.5841\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6032 - val_loss: 0.5796\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6016 - val_loss: 0.5803\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6015 - val_loss: 0.5812\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6035 - val_loss: 0.5890\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6072 - val_loss: 0.5864\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6071 - val_loss: 0.5840\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6040 - val_loss: 0.5815\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6049 - val_loss: 0.5850\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6050 - val_loss: 0.5838\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6046 - val_loss: 0.5858\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6027 - val_loss: 0.5835\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6046 - val_loss: 0.5793\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6025 - val_loss: 0.5820\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6030 - val_loss: 0.5806\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6011 - val_loss: 0.5756\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5985 - val_loss: 0.5759\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5986 - val_loss: 0.5789\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6015 - val_loss: 0.5819\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6030 - val_loss: 0.5744\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5998 - val_loss: 0.5780\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6009 - val_loss: 0.5764\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6021 - val_loss: 0.5868\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6036 - val_loss: 0.5815\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6050 - val_loss: 0.5820\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6032 - val_loss: 0.5832\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6011 - val_loss: 0.5782\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6013 - val_loss: 0.5796\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6010 - val_loss: 0.5787\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6021 - val_loss: 0.5843\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6014 - val_loss: 0.5810\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6006 - val_loss: 0.5770\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.5989 - val_loss: 0.5744\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5986 - val_loss: 0.5773\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5983 - val_loss: 0.5803\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6015 - val_loss: 0.5799\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.6032 - val_loss: 0.5797\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6015 - val_loss: 0.5830\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6039 - val_loss: 0.5827\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6021 - val_loss: 0.5797\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6008 - val_loss: 0.5776\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6009 - val_loss: 0.5792\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5999 - val_loss: 0.5783\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6025 - val_loss: 0.5768\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.6021 - val_loss: 0.5781\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6025 - val_loss: 0.5785\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6035 - val_loss: 0.5849\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6004 - val_loss: 0.5834\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6038 - val_loss: 0.5793\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6026 - val_loss: 0.5805\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6021 - val_loss: 0.5839\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6011 - val_loss: 0.5778\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6003 - val_loss: 0.5780\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5998 - val_loss: 0.5800\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6010 - val_loss: 0.5788\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6034 - val_loss: 0.5814\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.5989 - val_loss: 0.5834\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6030 - val_loss: 0.5828\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00152: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,epochs = 1000, validation_data=dataset_val, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../outputs/mmp_earlystop_00511.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../outputs/mmp_earlystop_00511.pb/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../outputs/mmp_earlystop_00511.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../outputs/model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_test, \n",
    "                                                     targets = Y_test, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0639604330062866"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 360)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted = model.predict(dataset_test)\n",
    "# it is 360 long not 380, so it must be only cortex\n",
    "Y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import npp\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test[9:,:], Y_predicted,multioutput='raw_values')\n",
    "r = npp.mcorr(Y_test[9:,:], Y_predicted)\n",
    "r = np.append(r, np.zeros(20))\n",
    "r2 = np.append(r2, np.zeros(20))\n",
    "\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.append(r2, np.zeros(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import nilearn.plotting as plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import hcp_utils as hcp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380,)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.60541544 -0.58934379 -0.55266707 -0.50050411 -0.43722121 -0.43558113\n",
      " -0.41723345 -0.41123071 -0.40820145 -0.40738757 -0.400753   -0.3961009\n",
      " -0.3959338  -0.39348458 -0.39226126 -0.38949863 -0.38928398 -0.38773321\n",
      " -0.38592725 -0.3858073  -0.38297276 -0.37757682 -0.37720798 -0.3770676\n",
      " -0.36981633 -0.36366198 -0.3629101  -0.36234956 -0.35585319 -0.35490243\n",
      " -0.35271716 -0.35221839 -0.35212463 -0.3504849  -0.34967885 -0.34889434\n",
      " -0.34572595 -0.34560158 -0.34537841 -0.34528762 -0.33808161 -0.33682879\n",
      " -0.33605215 -0.3334054  -0.33048122 -0.32553797 -0.3253692  -0.32113236\n",
      " -0.32099961 -0.31846672 -0.3184623  -0.31648036 -0.31632305 -0.31533863\n",
      " -0.31523559 -0.31514684 -0.31408676 -0.31331144 -0.30981342 -0.30578311\n",
      " -0.29900258 -0.29684165 -0.29563076 -0.2955406  -0.29374022 -0.29264572\n",
      " -0.28788534 -0.28646566 -0.28299045 -0.28288196 -0.28215919 -0.28147888\n",
      " -0.28112779 -0.28049498 -0.28011843 -0.2764798  -0.27533344 -0.27441443\n",
      " -0.27425846 -0.27261367 -0.27164958 -0.26756589 -0.26630498 -0.266021\n",
      " -0.26510744 -0.26448562 -0.26053517 -0.25926944 -0.25459568 -0.25458344\n",
      " -0.25330525 -0.25192683 -0.25067802 -0.24959725 -0.24828424 -0.24809929\n",
      " -0.24784285 -0.24664648 -0.24626951 -0.2456209  -0.24525675 -0.24430683\n",
      " -0.24394069 -0.24208827 -0.23814138 -0.23690705 -0.23201227 -0.23105714\n",
      " -0.23002298 -0.22779789 -0.22751941 -0.22546198 -0.22529994 -0.22468818\n",
      " -0.22415225 -0.22371477 -0.22290212 -0.2227214  -0.22259221 -0.22239848\n",
      " -0.22209303 -0.22169463 -0.22087642 -0.22056415 -0.22045297 -0.21992405\n",
      " -0.21983658 -0.21837977 -0.2152579  -0.21507545 -0.21339179 -0.20980872\n",
      " -0.20936245 -0.20897883 -0.2083032  -0.20819493 -0.2075784  -0.20473159\n",
      " -0.20229926 -0.20147005 -0.20110946 -0.19895928 -0.19696136 -0.19554964\n",
      " -0.19535322 -0.19500985 -0.19287816 -0.19012931 -0.18833762 -0.18739984\n",
      " -0.18648376 -0.18617706 -0.18419132 -0.18274587 -0.17871051 -0.17830754\n",
      " -0.17236742 -0.16859156 -0.168114   -0.16728216 -0.16123816 -0.15646628\n",
      " -0.15398219 -0.15294064 -0.15024279 -0.14832965 -0.14707636 -0.14237826\n",
      " -0.14237269 -0.14190071 -0.13332085 -0.12310095 -0.11315969 -0.10315583\n",
      " -0.09123321 -0.07950798 -0.07441602 -0.06935119 -0.06396981 -0.04379093\n",
      "  0.        ]\n",
      "[-0.55945029 -0.55880815 -0.54905293 -0.49775337 -0.47669904 -0.46128466\n",
      " -0.43816289 -0.4202706  -0.40917171 -0.40567174 -0.40190566 -0.40146646\n",
      " -0.39715329 -0.39177203 -0.38841676 -0.3880555  -0.37339268 -0.37181696\n",
      " -0.37062136 -0.36912917 -0.36716507 -0.36678757 -0.36522406 -0.36455226\n",
      " -0.3645352  -0.36261772 -0.36150803 -0.35907707 -0.35812744 -0.35794989\n",
      " -0.35728753 -0.3553511  -0.35518348 -0.34967793 -0.34825878 -0.34614136\n",
      " -0.34524568 -0.34484369 -0.3446023  -0.34344892 -0.34230026 -0.34022087\n",
      " -0.33951706 -0.33894347 -0.33330858 -0.3315204  -0.32951044 -0.3253625\n",
      " -0.32515144 -0.32203778 -0.32151362 -0.32073383 -0.32051634 -0.3179068\n",
      " -0.31600469 -0.31522594 -0.3131561  -0.31310559 -0.31268494 -0.31131803\n",
      " -0.30610742 -0.30556694 -0.30526626 -0.30453188 -0.30417992 -0.30345961\n",
      " -0.30250667 -0.30175175 -0.30169267 -0.30160347 -0.30097106 -0.30025977\n",
      " -0.29943692 -0.29867038 -0.29586039 -0.29534613 -0.29391559 -0.29377133\n",
      " -0.29227961 -0.29028092 -0.28962095 -0.28911068 -0.28825484 -0.28629378\n",
      " -0.28481228 -0.28427864 -0.28097091 -0.28081718 -0.27601337 -0.27592935\n",
      " -0.27544329 -0.27212474 -0.27183775 -0.27148166 -0.27117493 -0.2704555\n",
      " -0.26742637 -0.26733331 -0.26709242 -0.26700627 -0.26407668 -0.26404111\n",
      " -0.26370325 -0.26344715 -0.26262666 -0.26168474 -0.2583989  -0.2569664\n",
      " -0.2560207  -0.25301061 -0.25008887 -0.24905177 -0.24868125 -0.24849307\n",
      " -0.24743915 -0.24597609 -0.24424316 -0.24358512 -0.24325206 -0.24044124\n",
      " -0.23811658 -0.23671042 -0.23572949 -0.23496915 -0.22994638 -0.22983179\n",
      " -0.22971015 -0.22720921 -0.2262288  -0.22514176 -0.22442138 -0.22416315\n",
      " -0.22013189 -0.21851229 -0.21733102 -0.21629085 -0.2159219  -0.21404769\n",
      " -0.21389092 -0.21334278 -0.21275692 -0.21114278 -0.21078715 -0.20905371\n",
      " -0.20733148 -0.20516387 -0.20494661 -0.19777556 -0.1962056  -0.19617927\n",
      " -0.19447262 -0.19247059 -0.19050018 -0.19001834 -0.18703874 -0.18662504\n",
      " -0.18544341 -0.1846139  -0.18430441 -0.18307237 -0.18128571 -0.17719035\n",
      " -0.16303216 -0.15893027 -0.15864034 -0.1543506  -0.14929994 -0.14923469\n",
      " -0.14472903 -0.14341537 -0.1426456  -0.13916356 -0.12174373 -0.12085052\n",
      " -0.11934996 -0.11022301 -0.09726913 -0.09524254 -0.0945237  -0.05827374\n",
      "  0.        ]\n",
      "[-0.60541544 -0.58934379 -0.55266707 -0.50050411 -0.43722121 -0.43558113\n",
      " -0.41723345 -0.41123071 -0.40820145 -0.40738757 -0.400753   -0.3961009\n",
      " -0.3959338  -0.39348458 -0.39226126 -0.38949863 -0.38928398 -0.38773321\n",
      " -0.38592725 -0.3858073  -0.38297276 -0.37757682 -0.37720798 -0.3770676\n",
      " -0.36981633 -0.36366198 -0.3629101  -0.36234956 -0.35585319 -0.35490243\n",
      " -0.35271716 -0.35221839 -0.35212463 -0.3504849  -0.34967885 -0.34889434\n",
      " -0.34572595 -0.34560158 -0.34537841 -0.34528762 -0.33808161 -0.33682879\n",
      " -0.33605215 -0.3334054  -0.33048122 -0.32553797 -0.3253692  -0.32113236\n",
      " -0.32099961 -0.31846672 -0.3184623  -0.31648036 -0.31632305 -0.31533863\n",
      " -0.31523559 -0.31514684 -0.31408676 -0.31331144 -0.30981342 -0.30578311\n",
      " -0.29900258 -0.29684165 -0.29563076 -0.2955406  -0.29374022 -0.29264572\n",
      " -0.28788534 -0.28646566 -0.28299045 -0.28288196 -0.28215919 -0.28147888\n",
      " -0.28112779 -0.28049498 -0.28011843 -0.2764798  -0.27533344 -0.27441443\n",
      " -0.27425846 -0.27261367 -0.27164958 -0.26756589 -0.26630498 -0.266021\n",
      " -0.26510744 -0.26448562 -0.26053517 -0.25926944 -0.25459568 -0.25458344\n",
      " -0.25330525 -0.25192683 -0.25067802 -0.24959725 -0.24828424 -0.24809929\n",
      " -0.24784285 -0.24664648 -0.24626951 -0.2456209  -0.24525675 -0.24430683\n",
      " -0.24394069 -0.24208827 -0.23814138 -0.23690705 -0.23201227 -0.23105714\n",
      " -0.23002298 -0.22779789 -0.22751941 -0.22546198 -0.22529994 -0.22468818\n",
      " -0.22415225 -0.22371477 -0.22290212 -0.2227214  -0.22259221 -0.22239848\n",
      " -0.22209303 -0.22169463 -0.22087642 -0.22056415 -0.22045297 -0.21992405\n",
      " -0.21983658 -0.21837977 -0.2152579  -0.21507545 -0.21339179 -0.20980872\n",
      " -0.20936245 -0.20897883 -0.2083032  -0.20819493 -0.2075784  -0.20473159\n",
      " -0.20229926 -0.20147005 -0.20110946 -0.19895928 -0.19696136 -0.19554964\n",
      " -0.19535322 -0.19500985 -0.19287816 -0.19012931 -0.18833762 -0.18739984\n",
      " -0.18648376 -0.18617706 -0.18419132 -0.18274587 -0.17871051 -0.17830754\n",
      " -0.17236742 -0.16859156 -0.168114   -0.16728216 -0.16123816 -0.15646628\n",
      " -0.15398219 -0.15294064 -0.15024279 -0.14832965 -0.14707636 -0.14237826\n",
      " -0.14237269 -0.14190071 -0.13332085 -0.12310095 -0.11315969 -0.10315583\n",
      " -0.09123321 -0.07950798 -0.07441602 -0.06935119 -0.06396981 -0.04379093\n",
      "  0.        ]\n",
      "[-0.55945029 -0.55880815 -0.54905293 -0.49775337 -0.47669904 -0.46128466\n",
      " -0.43816289 -0.4202706  -0.40917171 -0.40567174 -0.40190566 -0.40146646\n",
      " -0.39715329 -0.39177203 -0.38841676 -0.3880555  -0.37339268 -0.37181696\n",
      " -0.37062136 -0.36912917 -0.36716507 -0.36678757 -0.36522406 -0.36455226\n",
      " -0.3645352  -0.36261772 -0.36150803 -0.35907707 -0.35812744 -0.35794989\n",
      " -0.35728753 -0.3553511  -0.35518348 -0.34967793 -0.34825878 -0.34614136\n",
      " -0.34524568 -0.34484369 -0.3446023  -0.34344892 -0.34230026 -0.34022087\n",
      " -0.33951706 -0.33894347 -0.33330858 -0.3315204  -0.32951044 -0.3253625\n",
      " -0.32515144 -0.32203778 -0.32151362 -0.32073383 -0.32051634 -0.3179068\n",
      " -0.31600469 -0.31522594 -0.3131561  -0.31310559 -0.31268494 -0.31131803\n",
      " -0.30610742 -0.30556694 -0.30526626 -0.30453188 -0.30417992 -0.30345961\n",
      " -0.30250667 -0.30175175 -0.30169267 -0.30160347 -0.30097106 -0.30025977\n",
      " -0.29943692 -0.29867038 -0.29586039 -0.29534613 -0.29391559 -0.29377133\n",
      " -0.29227961 -0.29028092 -0.28962095 -0.28911068 -0.28825484 -0.28629378\n",
      " -0.28481228 -0.28427864 -0.28097091 -0.28081718 -0.27601337 -0.27592935\n",
      " -0.27544329 -0.27212474 -0.27183775 -0.27148166 -0.27117493 -0.2704555\n",
      " -0.26742637 -0.26733331 -0.26709242 -0.26700627 -0.26407668 -0.26404111\n",
      " -0.26370325 -0.26344715 -0.26262666 -0.26168474 -0.2583989  -0.2569664\n",
      " -0.2560207  -0.25301061 -0.25008887 -0.24905177 -0.24868125 -0.24849307\n",
      " -0.24743915 -0.24597609 -0.24424316 -0.24358512 -0.24325206 -0.24044124\n",
      " -0.23811658 -0.23671042 -0.23572949 -0.23496915 -0.22994638 -0.22983179\n",
      " -0.22971015 -0.22720921 -0.2262288  -0.22514176 -0.22442138 -0.22416315\n",
      " -0.22013189 -0.21851229 -0.21733102 -0.21629085 -0.2159219  -0.21404769\n",
      " -0.21389092 -0.21334278 -0.21275692 -0.21114278 -0.21078715 -0.20905371\n",
      " -0.20733148 -0.20516387 -0.20494661 -0.19777556 -0.1962056  -0.19617927\n",
      " -0.19447262 -0.19247059 -0.19050018 -0.19001834 -0.18703874 -0.18662504\n",
      " -0.18544341 -0.1846139  -0.18430441 -0.18307237 -0.18128571 -0.17719035\n",
      " -0.16303216 -0.15893027 -0.15864034 -0.1543506  -0.14929994 -0.14923469\n",
      " -0.14472903 -0.14341537 -0.1426456  -0.13916356 -0.12174373 -0.12085052\n",
      " -0.11934996 -0.11022301 -0.09726913 -0.09524254 -0.0945237  -0.05827374\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "from analysis import plot_32k_results\n",
    "plot_32k_results(hcp.unparcellate(r2, hcp.mmp),'r2',100610,'as_scores','HCP_MMP_LSTM10_e511_r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to encoding model simple ridgecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import simple_ridgeCV\n",
    "from analysis import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import nilearn.plotting as plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import hcp_utils as hcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3e5062e5866a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvertex_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_HCP_vertex_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "vertex_info = hcp.get_HCP_vertex_info(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=100610\n",
    "feature='as_scores'\n",
    "n_movies=[1,2,3,4]\n",
    "X,Y = load_data_HCP_MMP(subject,feature,n_movies)\n",
    "\n",
    "X = hrf_tools.apply_optimal_hrf_10hz(X,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mean,corr_mean,weights_mean = simple_ridgeCV(X,Y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vertex_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c07f9381bd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorr_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munparcellate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'32k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvertex_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100610\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'as_scores'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HCP_7T'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HCP_MMP_ridgecv_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#plot_32k_results(hcp.unparcellate(corr_mean, hcp.mmp),'r',100610,'as_scores','HCP_MMP_ridgecv_r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vertex_info' is not defined"
     ]
    }
   ],
   "source": [
    "corr_mean = np.append(corr_mean, np.zeros(20))\n",
    "plot_results(hcp.unparcellate(corr_mean, hcp.mmp),'r','32k',vertex_info,100610,'as_scores','HCP_7T','HCP_MMP_ridgecv_r')\n",
    "#plot_32k_results(hcp.unparcellate(corr_mean, hcp.mmp),'r',100610,'as_scores','HCP_MMP_ridgecv_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_32k_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9391eb211d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_32k_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munparcellate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100610\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'as_scores'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HCP_MMP_ridgecv_r2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_32k_results' is not defined"
     ]
    }
   ],
   "source": [
    "scores_mean = np.append(scores_mean, np.zeros(20))\n",
    "plot_32k_results(hcp.unparcellate(scores_mean, hcp.mmp),'r2',100610,'as_scores','HCP_MMP_ridgecv_r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
