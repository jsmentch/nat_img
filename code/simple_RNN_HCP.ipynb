{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make a very simple LSTM model with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see how long this will take to run for 7t data with a not too complicated model and what kind of resources we are talking about - single run single subject.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import hrf_tools\n",
    "#import hcp_utils as hcp\n",
    "#from analysis import plot_59k_results\n",
    "\n",
    "#import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5561804427975421796\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10770692224\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5732604921821330734\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9211, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject=100610\n",
    "feature='rms'\n",
    "n_movies=4\n",
    "scaler = StandardScaler()\n",
    "\n",
    "stim = ['tfMRI_MOVIE1_7T_AP','tfMRI_MOVIE2_7T_PA','tfMRI_MOVIE3_7T_PA','tfMRI_MOVIE4_7T_AP']\n",
    "stim_feat = ['7T_MOVIE1_CC1_v2', '7T_MOVIE2_HO1_v2', '7T_MOVIE3_CC2_v2', '7T_MOVIE4_HO2_v2']\n",
    "    \n",
    "i=0\n",
    "X = np.load(f'../sourcedata/data/HCP_7T_movie_FIX/features/{stim_feat[i]}_rms.npy')\n",
    "X.shape#plt.plot(X[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = np.load(f'../sourcedata/data/HCP_7T_movie_FIX/features/{stim_feat[i]}_as_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resample(X, 921, axis=0) #resample to 1hz for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hrf = hrf_tools.apply_optimal_hrf_10hz(X,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921, 360)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = nb.load('../sourcedata/data/parcellations/parcellated/sub100610_tfMRI_MOVIE1_7T_AP.ptseries.nii')\n",
    "Y = img.get_fdata()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 360)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = nb.load('../sourcedata/data/parcellations/parcellated/sub100610_tfMRI_MOVIE2_7T_PA.ptseries.nii')\n",
    "Y_test = img.get_fdata()\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 1024)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "X_test = np.load(f'../sourcedata/data/HCP_7T_movie_FIX/features/{stim_feat[i]}_rms.npy')\n",
    "X_test = resample(X, 918, axis=0) #resample to 1hz for now \n",
    "X_test_hrf = hrf_tools.apply_optimal_hrf_10hz(X_test,1)\n",
    "X_test.shape#plt.plot(X[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/100610/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "# img = nb.load(im_file)\n",
    "# img_y = img.get_fdata()\n",
    "# Y = img_y\n",
    "#Y is time x brain\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(921, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X is time x embed\n",
    "X_hrf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### design a simple(?) lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "#         layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "#         layers.Dense(4, name=\"layer3\"),\n",
    "#     ]\n",
    "# )\n",
    "# # Call model on a test input\n",
    "# x = tf.ones((3, 3))\n",
    "# y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               450000    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 360)               108360    \n",
      "=================================================================\n",
      "Total params: 638,860\n",
      "Trainable params: 638,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "time_steps = 10\n",
    "input_units = 1024\n",
    "input_shape = (time_steps,input_units)\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "#model.add(layers.Embedding(input_dim=1024, output_dim=1024))\n",
    "model.add(keras.Input(shape=input_shape))\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(100))\n",
    "#model.add(layers.UpSampling1D(size=10))\n",
    "#model.add(layers.Dense(17049))\n",
    "model.add(layers.Dense(200))\n",
    "model.add(layers.Dense(300))\n",
    "\n",
    "model.add(layers.Dense(360))\n",
    "\n",
    "\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "#model.add(layers.Dense(1721))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset = tf.data.Dataset.from_tensor_slices((np.expand_dims(x_train,0), np.expand_dims(y_train,0)))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X_hrf, Y))\n",
    "\n",
    "# dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/api/preprocessing/timeseries/\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_hrf, \n",
    "                                                     targets = Y, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, None, 1024), (None, 360)), types: (tf.float32, tf.float64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Buffer size to shuffle the dataset\n",
    "# # (TF data is designed to work with possibly infinite sequences,\n",
    "# # so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# # it maintains a buffer in which it shuffles elements).\n",
    "# BUFFER_SIZE = 10000\n",
    "\n",
    "# dataset = (\n",
    "#     dataset\n",
    "#     .shuffle(BUFFER_SIZE)\n",
    "#     .batch(batch_size, drop_remainder=True)\n",
    "#     .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#simple_rnn = layers.SimpleRNN(18, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_sequence_output, final_state = simple_rnn(np.expand_dims(x_train,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\"),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", 'mean_squared_error'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 4718.5742 - accuracy: 0.9890 - mean_squared_error: 4718.5742\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 4690.4814 - accuracy: 0.9890 - mean_squared_error: 4690.4814\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4712.2471 - accuracy: 0.9890 - mean_squared_error: 4712.2471\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4682.0088 - accuracy: 0.9890 - mean_squared_error: 4682.0088\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4709.7871 - accuracy: 0.9890 - mean_squared_error: 4709.7871\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4676.9424 - accuracy: 0.9890 - mean_squared_error: 4676.9424\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4709.8823 - accuracy: 0.9890 - mean_squared_error: 4709.8823\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4681.3809 - accuracy: 0.9890 - mean_squared_error: 4681.3809\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4724.6978 - accuracy: 0.9890 - mean_squared_error: 4724.6978\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4709.4922 - accuracy: 0.9890 - mean_squared_error: 4709.4922\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4779.0815 - accuracy: 0.9890 - mean_squared_error: 4779.0815\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4808.4375 - accuracy: 0.9890 - mean_squared_error: 4808.4375\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4941.1313 - accuracy: 0.9890 - mean_squared_error: 4941.1313\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4965.4355 - accuracy: 0.9890 - mean_squared_error: 4965.4355\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4996.7266 - accuracy: 0.9890 - mean_squared_error: 4996.7266\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4945.5986 - accuracy: 0.9890 - mean_squared_error: 4945.5986\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5050.7603 - accuracy: 0.9890 - mean_squared_error: 5050.7603\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5109.1055 - accuracy: 0.9890 - mean_squared_error: 5109.1055: 0s - loss: 4790.7573 - accuracy: 0.9948 - mean_squared_error: 4790.75\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5177.1748 - accuracy: 0.9890 - mean_squared_error: 5177.1748\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5139.9941 - accuracy: 0.9890 - mean_squared_error: 5139.9941\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model.save('../outputs/model.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../outputs/model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.keras.preprocessing.timeseries_dataset_from_array(data = X_test_hrf, \n",
    "                                                     targets = Y_test, \n",
    "                                                    sequence_length=time_steps,\n",
    "                                                     batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
