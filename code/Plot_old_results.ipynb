{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036ebe2-a6d3-4feb-81f6-c374bbb293f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "import hrf_tools\n",
    "import hcp_utils as hcp\n",
    "from analysis import plot_results\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5a965dc-b2c6-4c87-9297-5a8fb2feb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from nilearn_plotting_custom import plot_surf\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import npp\n",
    "import hcp_utils as hcp\n",
    "from hcp_tools import load_flatmaps_59k\n",
    "from hcp_tools import load_meshes\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(\"paper\", \"white\")\n",
    "#%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "def plot_results(scores,score_type,data_type,vertex_info,subject,feature,dataset,title):\n",
    "    '''Inputs:\n",
    "        scores = data to plot\n",
    "        score_type = r2, r, p, z, d, raw\n",
    "        data_type = 32k (3T) or 59k (7T)\n",
    "        vertex info = None or the vertex info if it is 59k data beacuse hcp_utils doesnt by default\n",
    "        subject = eg 100610 subject id for file naming\n",
    "        feature = eg as_scores plotted feature for file naming\n",
    "        dataset = eg merlin or HCP_7T which dataset?\n",
    "        title = \n",
    "    '''\n",
    "    scratch_dir = '../tmp'\n",
    "#     scratch_dir = '/scratch/scratch/Fri/jsmentch/tmp'\n",
    "#     if not os.path.exists(scratch_dir):\n",
    "#         os.mkdir(scratch_dir)\n",
    "    if score_type == 'r2':\n",
    "        v=[0,0.5]\n",
    "        threshold=0.01\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'r':\n",
    "        v=[0,1]\n",
    "        threshold=None\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'p':\n",
    "        v=[0,0.05]\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'z':\n",
    "        v=[-10,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    if score_type == 'd':\n",
    "        v=[0,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='inferno'\n",
    "    if score_type == 'raw':\n",
    "        v=[-10,10]\n",
    "        threshold=1\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    save_dir=f'../outputs/figures/{dataset}/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)    \n",
    "    if data_type == '59k':\n",
    "        flatmeshes=load_flatmaps_59k() #load flatmaps\n",
    "        surf_path_msm = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.L.inflated_1.6mm_MSMAll.59k_fs_LR.surf.gii'\n",
    "        mesh59k_msm = load_meshes(example_filename=surf_path_msm) #load other meshes\n",
    "        # get data from results in plotting format\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        # sulcal depth paths\n",
    "        sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "        sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "        # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,flatmeshes.flat_left,sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,flatmeshes.flat_right,sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,mesh59k_msm.very_inflated_left,sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,mesh59k_msm.very_inflated_right,sulc_right,'right'),\\\n",
    "        ]\n",
    "    elif data_type == '32k':\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0)\n",
    "    #     # sulcal depth paths\n",
    "    #     sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "    #     sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "    #     # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,hcp.mesh.flat_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,hcp.mesh.flat_right,hcp.mesh.sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,hcp.mesh.very_inflated_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,hcp.mesh.very_inflated_right,hcp.mesh.sulc_right,'right'),\\\n",
    "        ]\n",
    "    # plot each hemi and mesh, save to outputs dir\n",
    "    for name, data, mesh, sulc, hemi in params:\n",
    "        #figure, axes = plt.subplots(subplot_kw=dict(projection=\"3d\"), figsize=(6,4))\n",
    "        plot_surf(mesh,\\\n",
    "                data, \\\n",
    "                  cmap=cmap,symmetric_cmap=symmetric_cmap, avg_method='median',#figure=fig,\\\n",
    "                bg_map=sulc, colorbar=True, vmin=v[0], vmax=v[1], threshold=threshold, hemi=hemi, \\\n",
    "                data_alpha=np.where(data>0,1,0),\\\n",
    "                data_remove=np.zeros(data.shape),output_file=f'{scratch_dir}/{name}.png')\n",
    "#combine saved maps into one with PIL\n",
    "#     if notebook==True:\n",
    "    area = (75, 140, 635, 560) #area to crop from each image\n",
    "#     else:\n",
    "#         area = (105, 190, 880, 780)\n",
    "        \n",
    "    img = Image.open(f'{scratch_dir}/flat_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    cropped = img.crop(area)\n",
    "    fL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    w,h = img.size\n",
    "    c_area = (690, 0, w-10, h) # area of colorbar to crop\n",
    "    cbar = img.crop(c_area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/flat_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    fR = img.crop(area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iL = img.crop(area)\n",
    "    #iL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iR = img.crop(area)\n",
    "\n",
    "    w,h=iR.size\n",
    "\n",
    "    new_im = Image.new('RGB', ( (w*2)+70 , h*2) ,(255, 255, 255, 1))\n",
    "    new_im.paste(fL,(0,h))\n",
    "    new_im.paste(fR,(w,h))\n",
    "    new_im.paste(iL,(0,0))\n",
    "    new_im.paste(iR,(w,0))\n",
    "    new_im.paste(cbar,(w*2,int(round(h/4))))\n",
    "\n",
    "    w,h=new_im.size\n",
    "\n",
    "    draw = ImageDraw.Draw(new_im)\n",
    "    draw.text((0,0),f\"{title}_{subject}_{feature}_{score_type}\",(0,0,0))\n",
    "\n",
    "    new_im.save(f'{save_dir}{title}_{subject}_{feature}_{score_type}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df600046-2f9f-4204-ad3c-79546538c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im_file = f'../sourcedata/data/budapest/brain/ds003017/derivatives/fmriprep/derivatives/cleaned/smoothed/sub-sid000005_run1_clean_smooth_space-fsLR_den-91k_bold.dtseries.nii'\n",
    "im_file = f'../../speech_face_analysis/data/fitlins_cifti/fitlins/task-MerlinMovie_space-fsLR_contrast-speech_stat-z_statmap.dscalar.nii'\n",
    "#im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/100610/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "img = nb.load(im_file)\n",
    "img_y = img.get_fdata()\n",
    "#img_y[np.isnan(img_y)] = 0\n",
    "Y=img_y\n",
    "\n",
    "vertex_info = hcp.get_HCP_vertex_info(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cdc070-7a26-4936-8ae9-648bde6ff8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(Y[0],'z','32k',vertex_info=vertex_info,subject='group',feature='speech', dataset='merlin',title=f'glm' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c880b98-fb36-4358-91f3-ac9dcbc9e56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/gablab/jsmentch/projects/nat_img/code/nilearn_plotting_custom.py:184: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  axes = Axes3D(figure, rect=[0, 0, 1, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1743319  0.17924121 0.18096912 ... 0.81205445 0.81735    0.82800209]\n",
      "[0.19327798 0.19757743 0.19782137 ... 0.79031321 0.79250868 0.79252901]\n",
      "[0.1743319  0.17924121 0.18096912 ... 0.81205445 0.81735    0.82800209]\n",
      "[0.19327798 0.19757743 0.19782137 ... 0.79031321 0.79250868 0.79252901]\n"
     ]
    }
   ],
   "source": [
    "#im_file = f'../sourcedata/data/budapest/brain/ds003017/derivatives/fmriprep/derivatives/cleaned/smoothed/sub-sid000005_run1_clean_smooth_space-fsLR_den-91k_bold.dtseries.nii'\n",
    "im_file = f'../../speech_face_analysis/data/fitlins_cifti/fitlins/task-MerlinMovie_space-fsLR_contrast-anyFaces_stat-z_statmap.dscalar.nii'\n",
    "#im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/100610/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "img = nb.load(im_file)\n",
    "img_y = img.get_fdata()\n",
    "#img_y[np.isnan(img_y)] = 0\n",
    "Y=img_y\n",
    "\n",
    "vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "plot_results(Y[0],'z','32k',vertex_info=vertex_info,subject='group',feature='any_faces', dataset='merlin',title=f'glm' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9f1603b-1593-4318-b926-3ee18b1a6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/gablab/jsmentch/projects/nat_img/code/nilearn_plotting_custom.py:184: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  axes = Axes3D(figure, rect=[0, 0, 1, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14582987 0.15315018 0.16070432 ... 0.79143999 0.7933514  0.80179009]\n",
      "[0.18549169 0.18847064 0.18904    ... 0.78097806 0.78253362 0.78632595]\n",
      "[0.14582987 0.15315018 0.16070432 ... 0.79143999 0.7933514  0.80179009]\n",
      "[0.18549169 0.18847064 0.18904    ... 0.78097806 0.78253362 0.78632595]\n"
     ]
    }
   ],
   "source": [
    "#im_file = f'../sourcedata/data/budapest/brain/ds003017/derivatives/fmriprep/derivatives/cleaned/smoothed/sub-sid000005_run1_clean_smooth_space-fsLR_den-91k_bold.dtseries.nii'\n",
    "im_file = f'../../speech_face_analysis/data/fitlins_cifti/fitlins/task-MerlinMovie_space-fsLR_contrast-faceAndSpeech_stat-z_statmap.dscalar.nii'\n",
    "#im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/100610/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "img = nb.load(im_file)\n",
    "img_y = img.get_fdata()\n",
    "#img_y[np.isnan(img_y)] = 0\n",
    "Y=img_y\n",
    "\n",
    "vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "plot_results(Y[0],'z','32k',vertex_info=vertex_info,subject='group',feature='face_speech', dataset='merlin',title=f'glm' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910cb15-0c3b-4b1b-b1c5-d5dcc0a31d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900df01-6d7c-4fd0-8d7a-faace1ff9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7637a6a0-1588-461c-805f-648ed65b06e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14584446 0.15315292 0.16070086 ...        nan        nan        nan]\n",
      "[0.18548929 0.18846302 0.18903682 ...        nan        nan        nan]\n",
      "[0.14584446 0.15315292 0.16070086 ...        nan        nan        nan]\n",
      "[0.18548929 0.18846302 0.18903682 ...        nan        nan        nan]\n"
     ]
    }
   ],
   "source": [
    "#im_file = f'../sourcedata/data/budapest/brain/ds003017/derivatives/fmriprep/derivatives/cleaned/smoothed/sub-sid000005_run1_clean_smooth_space-fsLR_den-91k_bold.dtseries.nii'\n",
    "im_file = f'../../speech_face_analysis/data/fitlins_cifti_nan/fitlins/task-MerlinMovie_space-fsLR_contrast-faceAndSpeech_stat-z_statmap.dscalar.nii'\n",
    "#im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/100610/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "img = nb.load(im_file)\n",
    "img_y = img.get_fdata()\n",
    "#img_y[np.isnan(img_y)] = 0\n",
    "Y=img_y\n",
    "\n",
    "vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "plot_results(Y[0],'z','32k',vertex_info=vertex_info,subject='group',feature='face_speech', dataset='merlin',title=f'glm_dec_z' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968ea1c-98c8-4cc8-a9f4-ea868624abc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec229660-85c3-463f-9b31-24f1b3a5420a",
   "metadata": {},
   "source": [
    "## plot character encoding model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a8826b-28cf-4cd4-b8f7-9521c038388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 8.24201966e-07 2.26300302e-06 ... 5.32979877e-01\n",
      " 5.39006600e-01 5.57462448e-01]\n",
      "[0.00000000e+00 1.17110346e-06 1.68476191e-06 ... 5.07091557e-01\n",
      " 5.12947641e-01 5.13103837e-01]\n",
      "[0.00000000e+00 8.24201966e-07 2.26300302e-06 ... 5.32979877e-01\n",
      " 5.39006600e-01 5.57462448e-01]\n",
      "[0.00000000e+00 1.17110346e-06 1.68476191e-06 ... 5.07091557e-01\n",
      " 5.12947641e-01 5.13103837e-01]\n"
     ]
    }
   ],
   "source": [
    "Y=np.load('../outputs/char_encoding_train_all_test_all.npy')\n",
    "plot_results(Y,'r2','32k',vertex_info=vertex_info,subject='group',feature='char', dataset='merlin',title=f'train_all_test_all_thresh' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37838703-96f1-4c19-b117-cf82d444eef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 9.56456634e-06 1.45001426e-05 ... 7.41044472e-01\n",
      " 7.59792158e-01 7.75747210e-01]\n",
      "[0.00000000e+00 3.76012762e-06 4.27633961e-06 ... 7.86080263e-01\n",
      " 7.92836706e-01 8.12508197e-01]\n",
      "[0.00000000e+00 9.56456634e-06 1.45001426e-05 ... 7.41044472e-01\n",
      " 7.59792158e-01 7.75747210e-01]\n",
      "[0.00000000e+00 3.76012762e-06 4.27633961e-06 ... 7.86080263e-01\n",
      " 7.92836706e-01 8.12508197e-01]\n"
     ]
    }
   ],
   "source": [
    "Y=np.load('../outputs/char_encoding_train_all.npy')\n",
    "plot_results(Y,'r2','32k',vertex_info=vertex_info,subject='group',feature='char', dataset='merlin',title=f'train_all_test_one_thresh' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c53afc9-ae8c-44a7-89af-3b3c30630a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 3.18216402e-05 7.09235171e-05 ... 9.63270054e-01\n",
      " 9.80186634e-01 9.97936896e-01]\n",
      "[0.00000000e+00 1.55418429e-05 2.52948558e-05 ... 9.88209520e-01\n",
      " 9.88875569e-01 1.00079341e+00]\n",
      "[0.00000000e+00 3.18216402e-05 7.09235171e-05 ... 9.63270054e-01\n",
      " 9.80186634e-01 9.97936896e-01]\n",
      "[0.00000000e+00 1.55418429e-05 2.52948558e-05 ... 9.88209520e-01\n",
      " 9.88875569e-01 1.00079341e+00]\n"
     ]
    }
   ],
   "source": [
    "Y=np.load('../outputs/char_encoding_train_one.npy')\n",
    "plot_results(Y,'r2','32k',vertex_info=vertex_info,subject='group',feature='char', dataset='merlin',title=f'train_one_test_one_thresh' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43a4672-3d43-45df-8d51-4f8594113019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/gablab/jsmentch/projects/nat_img/code/nilearn_plotting_custom.py:184: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  axes = Axes3D(figure, rect=[0, 0, 1, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 3.67677658e-05 9.21799309e-05 ... 8.72929386e-01\n",
      " 8.94747575e-01 9.11597611e-01]\n",
      "[0.00000000e+00 7.64043521e-06 1.03407433e-05 ... 9.97475954e-01\n",
      " 9.98270789e-01 1.00784540e+00]\n",
      "[0.00000000e+00 3.67677658e-05 9.21799309e-05 ... 8.72929386e-01\n",
      " 8.94747575e-01 9.11597611e-01]\n",
      "[0.00000000e+00 7.64043521e-06 1.03407433e-05 ... 9.97475954e-01\n",
      " 9.98270789e-01 1.00784540e+00]\n"
     ]
    }
   ],
   "source": [
    "Y=np.load('../outputs/char_encoding_train_one2.npy')\n",
    "plot_results(Y,'r2','32k',vertex_info=vertex_info,subject='group',feature='char', dataset='merlin',title=f'train_one_test_one2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d282b-4e2d-490e-9215-19a925583bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22b5a6-6002-49d3-8f86-3a286ff6ac72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5aaacf-17ed-4901-b635-3310984c7e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7efc5ab7-2522-4ad3-aaa1-611a031d01cb",
   "metadata": {},
   "source": [
    "## hcp plot group encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a671fa1-1200-487e-aba6-ceb562fa81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "import numpy as np\n",
    "\n",
    "import nilearn.plotting as nlp\n",
    "from nilearn_plotting_custom import plot_surf\n",
    "import hcp_utils as hcp\n",
    "from hcp_tools import extract_cortex\n",
    "from hcp_tools import load_meshes\n",
    "#from analysis import load_data\n",
    "from hcp_tools import load_flatmaps_59k\n",
    "from analysis import simple_ridgeCV\n",
    "#from analysis import plot_59k_results\n",
    "import os\n",
    "import hrf_tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(\"paper\", \"white\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901ae369-4933-4b04-92dd-26ca664dd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "subject=100610\n",
    "feature='as_scores'\n",
    "n_movies=1\n",
    "\n",
    "def load_data_AS(subject,feature,n_movies):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    # Inputs: subject = HCP id eg 100610\n",
    "    #         feature='mfs'\n",
    "    #         n_movies is a number 1-4\n",
    "    # Returns: X feature data (2D; time x feature)\n",
    "    #          Y brain data (2D; time x grayordinate)\n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    y_l=[]\n",
    "    x_l=[]\n",
    "    stim = ['tfMRI_MOVIE1_7T_AP','tfMRI_MOVIE2_7T_PA','tfMRI_MOVIE3_7T_PA','tfMRI_MOVIE4_7T_AP']\n",
    "    stim_feat = ['7T_MOVIE1_CC1_v2', '7T_MOVIE2_HO1_v2', '7T_MOVIE3_CC2_v2', '7T_MOVIE4_HO2_v2']\n",
    "    \n",
    "    for i in np.arange(n_movies):\n",
    "        #load brain image\n",
    "        im_file = f'../sourcedata/data/HCP_7T_movie_FIX/brain/HCP_7T_movie_FIX/{str(subject)}/MNINonLinear/Results/{stim[i]}/{stim[i]}_Atlas_1.6mm_MSMAll_hp2000_clean.dtseries.nii'\n",
    "        img = nb.load(im_file)\n",
    "        img_y = img.get_fdata()\n",
    "        img_y = scaler.fit_transform(img_y)\n",
    "        #img_y = scaler.transform(img_y)\n",
    "        \n",
    "        #load feature\n",
    "        feat_x = np.load(f'../sourcedata/data/HCP_7T_movie_FIX/features/{stim_feat[i]}_{feature}.npy')\n",
    "        feat_x = hrf_tools.apply_optimal_hrf_10hz(feat_x,2.08)\n",
    "        #feat_x = hrf_tools.resample_1hz(feat_x)\n",
    "\n",
    "        from scipy.signal import resample\n",
    "        feat_x = resample(feat_x, img_y.shape[0], axis=0)\n",
    "\n",
    "        #feat_x = feat_x[:img_y.shape[0],:]\n",
    "        #feat_x=feat_x.T\n",
    "        y_l.append(img_y)\n",
    "        x_l.append(feat_x)\n",
    "    Y=np.vstack(y_l)\n",
    "    X=np.vstack(x_l)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #X = scaler.fit_transform(X)\n",
    "    vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "    return X,Y,vertex_info\n",
    "\n",
    "X,Y,vertex_info = load_data_AS(subject,feature,n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58aee6b-b199-4fa1-8ee5-77a7a3e5101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/vast/gablab/jsmentch/projects/nat_img/code/nilearn_plotting_custom.py:184: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  axes = Axes3D(figure, rect=[0, 0, 1, 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15546215 -0.15077404 -0.14981797 ...  0.09955957  0.09981586\n",
      "  0.09995978]\n",
      "[-0.19606981 -0.19449887 -0.19166744 ...  0.08164116  0.08302976\n",
      "  0.08354594]\n",
      "[-0.15546215 -0.15077404 -0.14981797 ...  0.09955957  0.09981586\n",
      "  0.09995978]\n",
      "[-0.19606981 -0.19449887 -0.19166744 ...  0.08164116  0.08302976\n",
      "  0.08354594]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "feature='as_scores'\n",
    "dataset='HCP_7T'\n",
    "\n",
    "#clean_path = f'../outputs/encoding_model/{dataset}/{feature}/'\n",
    "flist = glob.glob(f'../outputs/encoding_model/{dataset}/{feature}/*scores.npy')\n",
    "#all_=[]\n",
    "all_sub = []\n",
    "for s in flist:\n",
    "    cur = np.load(f'{s}')\n",
    "    all_sub.append(cur)\n",
    "    \n",
    "\n",
    "all_sub = np.array(all_sub)\n",
    "\n",
    "all_sub_mean = np.mean(all_sub,axis=0)\n",
    "\n",
    "\n",
    "#vertex_info = hcp.get_HCP_vertex_info(img)\n",
    "plot_results(all_sub_mean,'r2','59k',vertex_info,\"all\",feature,dataset,'ridgeCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75ae5c8a-77bf-475e-906b-dce6504657ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=192641\n",
    "#subject=105923\n",
    "\n",
    "scores=np.load(f'../outputs/encoding_model/HCP_7T/as_scores/ridgeCV_{subject}_as_scores_scores.npy')\n",
    "weights = np.load(f'../outputs/encoding_model/HCP_7T/as_scores/ridgeCV_{subject}_as_scores_weights.npy')\n",
    "corr = np.load(f'../outputs/encoding_model/HCP_7T/as_scores/ridgeCV_{subject}_as_scores_corr.npy')\n",
    "\n",
    "music_weight=weights[:,132]\n",
    "speech_weight=weights[:,0]\n",
    "animal_weight=weights[:,67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a98ac9-22da-4dfc-aadd-fcf3e2fd20bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#old!!\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from nilearn_plotting_custom import plot_surf\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import npp\n",
    "import hcp_utils as hcp\n",
    "from hcp_tools import load_flatmaps_59k\n",
    "from hcp_tools import load_meshes\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(\"paper\", \"white\")\n",
    "#%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "def plot_results(scores,score_type,data_type,vertex_info,subject,feature,dataset,title):\n",
    "    '''Inputs:\n",
    "        scores = data to plot\n",
    "        score_type = r2, r, p, z, d, raw\n",
    "        data_type = 32k (3T) or 59k (7T)\n",
    "        vertex info = None or the vertex info if it is 59k data beacuse hcp_utils doesnt by default\n",
    "        subject = eg 100610 subject id for file naming\n",
    "        feature = eg as_scores plotted feature for file naming\n",
    "        dataset = eg merlin or HCP_7T which dataset?\n",
    "        title = \n",
    "    '''\n",
    "    scratch_dir = '../tmp'\n",
    "#     scratch_dir = '/scratch/scratch/Fri/jsmentch/tmp'\n",
    "#     if not os.path.exists(scratch_dir):\n",
    "#         os.mkdir(scratch_dir)\n",
    "    if score_type == 'r2':\n",
    "        v=[0,0.5]\n",
    "        threshold=None\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'r':\n",
    "        v=[0,1]\n",
    "        threshold=None\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'p':\n",
    "        v=[0,0.05]\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'z':\n",
    "        v=[-10,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    if score_type == 'd':\n",
    "        v=[0,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='inferno'\n",
    "    if score_type == 'raw':\n",
    "        v=[-1.5,1.5]\n",
    "        threshold=None\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    save_dir=f'../outputs/figures/{dataset}/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)    \n",
    "    if data_type == '59k':\n",
    "        flatmeshes=load_flatmaps_59k() #load flatmaps\n",
    "        surf_path_msm = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.L.inflated_1.6mm_MSMAll.59k_fs_LR.surf.gii'\n",
    "        mesh59k_msm = load_meshes(example_filename=surf_path_msm) #load other meshes\n",
    "        # get data from results in plotting format\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        # sulcal depth paths\n",
    "        sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "        sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "        # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,flatmeshes.flat_left,sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,flatmeshes.flat_right,sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,mesh59k_msm.very_inflated_left,sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,mesh59k_msm.very_inflated_right,sulc_right,'right'),\\\n",
    "        ]\n",
    "    elif data_type == '32k':\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0)\n",
    "    #     # sulcal depth paths\n",
    "    #     sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "    #     sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "    #     # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,hcp.mesh.flat_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,hcp.mesh.flat_right,hcp.mesh.sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,hcp.mesh.very_inflated_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,hcp.mesh.very_inflated_right,hcp.mesh.sulc_right,'right'),\\\n",
    "        ]\n",
    "    # plot each hemi and mesh, save to outputs dir\n",
    "    for name, data, mesh, sulc, hemi in params:\n",
    "        #figure, axes = plt.subplots(subplot_kw=dict(projection=\"3d\"), figsize=(6,4))\n",
    "        plot_surf(mesh,\\\n",
    "                data, \\\n",
    "                  cmap=cmap,symmetric_cmap=symmetric_cmap, avg_method='median',#figure=fig,\\\n",
    "                bg_map=sulc, colorbar=True, vmin=v[0], vmax=v[1], threshold=threshold, hemi=hemi, \\\n",
    "                data_alpha=np.where(data>0,1,1),\\\n",
    "                data_remove=np.zeros(data.shape),output_file=f'{scratch_dir}/{name}.png')\n",
    "#combine saved maps into one with PIL\n",
    "#     if notebook==True:\n",
    "    area = (75, 140, 635, 560) #area to crop from each image\n",
    "#     else:\n",
    "#         area = (105, 190, 880, 780)\n",
    "        \n",
    "    img = Image.open(f'{scratch_dir}/flat_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    cropped = img.crop(area)\n",
    "    fL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    w,h = img.size\n",
    "    c_area = (690, 0, w-10, h) # area of colorbar to crop\n",
    "    cbar = img.crop(c_area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/flat_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    fR = img.crop(area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iL = img.crop(area)\n",
    "    #iL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iR = img.crop(area)\n",
    "\n",
    "    w,h=iR.size\n",
    "\n",
    "    new_im = Image.new('RGB', ( (w*2)+70 , h*2) ,(255, 255, 255, 1))\n",
    "    new_im.paste(fL,(0,h))\n",
    "    new_im.paste(fR,(w,h))\n",
    "    new_im.paste(iL,(0,0))\n",
    "    new_im.paste(iR,(w,0))\n",
    "    new_im.paste(cbar,(w*2,int(round(h/4))))\n",
    "\n",
    "    w,h=new_im.size\n",
    "\n",
    "    draw = ImageDraw.Draw(new_im)\n",
    "    draw.text((0,0),f\"{title}_{subject}_{feature}_{score_type}\",(0,0,0))\n",
    "\n",
    "    new_im.save(f'{save_dir}{title}_{subject}_{feature}_{score_type}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09babb92-94bd-48c3-be43-1ee8c355b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[-1.02260832 -0.98855968 -0.96570519 ...  1.95231854  1.95864161\n",
      "  2.00993231]\n",
      "[-0.94431338 -0.94313325 -0.9357573  ...  1.95445844  1.95812154\n",
      "  1.96603391]\n",
      "[-1.02260832 -0.98855968 -0.96570519 ...  1.95231854  1.95864161\n",
      "  2.00993231]\n",
      "[-0.94431338 -0.94313325 -0.9357573  ...  1.95445844  1.95812154\n",
      "  1.96603391]\n"
     ]
    }
   ],
   "source": [
    "plot_results(animal_weight,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_animal_weight_thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07a57b8-28ff-4fb3-83d1-a5eb2e31af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[0.02926834 0.03190657 0.0327309  ... 0.90649062 0.90804672 0.92063252]\n",
      "[0.10509504 0.11103206 0.11376734 ... 0.78836263 0.7928823  0.80054868]\n",
      "[0.02926834 0.03190657 0.0327309  ... 0.90649062 0.90804672 0.92063252]\n",
      "[0.10509504 0.11103206 0.11376734 ... 0.78836263 0.7928823  0.80054868]\n",
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[0.24166978 0.24260728 0.24288854 ... 0.97544058 0.98519983 0.98621906]\n",
      "[0.23217668 0.23998475 0.24000262 ... 0.95478453 0.9578788  0.9641425 ]\n",
      "[0.24166978 0.24260728 0.24288854 ... 0.97544058 0.98519983 0.98621906]\n",
      "[0.23217668 0.23998475 0.24000262 ... 0.95478453 0.9578788  0.9641425 ]\n"
     ]
    }
   ],
   "source": [
    "plot_results(music_weight,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_music_weight')\n",
    "plot_results(speech_weight,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_speech_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdb5b81e-6f33-410b-ab12-9303a6d08422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[-0.46633811 -0.46141254 -0.4540893  ...  0.44455788  0.44665544\n",
      "  0.4502424 ]\n",
      "[-0.74588741 -0.72454169 -0.64685502 ...  0.44073376  0.44169705\n",
      "  0.47836799]\n",
      "[-0.46633811 -0.46141254 -0.4540893  ...  0.44455788  0.44665544\n",
      "  0.4502424 ]\n",
      "[-0.74588741 -0.72454169 -0.64685502 ...  0.44073376  0.44169705\n",
      "  0.47836799]\n"
     ]
    }
   ],
   "source": [
    "#plot_results(corr,'r','59k',vertex_info,subject,feature,dataset,'ridgeCV_as_corr')\n",
    "plot_results(scores,'r2','59k',vertex_info,subject,feature,dataset,'ridgeCV_as_r2_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "471b9d8a-da6d-4669-bd39-dc8a69c99a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.215629261775001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c37200bd-d155-4559-b001-281481cf6b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NEW!!\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from nilearn_plotting_custom import plot_surf\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import npp\n",
    "import hcp_utils as hcp\n",
    "from hcp_tools import load_flatmaps_59k\n",
    "from hcp_tools import load_meshes\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(\"paper\", \"white\")\n",
    "#%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "def plot_results(scores,data_alpha,score_type,data_type,vertex_info,subject,feature,dataset,title):\n",
    "    '''Inputs:\n",
    "        scores = data to plot\n",
    "        score_type = r2, r, p, z, d, raw\n",
    "        data_type = 32k (3T) or 59k (7T)\n",
    "        vertex info = None or the vertex info if it is 59k data beacuse hcp_utils doesnt by default\n",
    "        subject = eg 100610 subject id for file naming\n",
    "        feature = eg as_scores plotted feature for file naming\n",
    "        dataset = eg merlin or HCP_7T which dataset?\n",
    "        title = \n",
    "    '''\n",
    "    scratch_dir = '../tmp'\n",
    "#     scratch_dir = '/scratch/scratch/Fri/jsmentch/tmp'\n",
    "#     if not os.path.exists(scratch_dir):\n",
    "#         os.mkdir(scratch_dir)\n",
    "    if score_type == 'r2':\n",
    "        v=[0,0.5]\n",
    "        threshold=0.001\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'r':\n",
    "        v=[0,1]\n",
    "        threshold=None\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'weights':\n",
    "        v=[0,6]\n",
    "        threshold=None\n",
    "        symmetric_cmap=False\n",
    "        cmap='tab10'\n",
    "    if score_type == 'p':\n",
    "        v=[0,0.05]\n",
    "        symmetric_cmap=False\n",
    "        cmap='inferno'\n",
    "    if score_type == 'z':\n",
    "        v=[-10,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    if score_type == 'd':\n",
    "        v=[0,10]\n",
    "        threshold=3\n",
    "        symmetric_cmap=True\n",
    "        cmap='inferno'\n",
    "    if score_type == 'raw':\n",
    "        v=[-1.5,1.5]\n",
    "        threshold=None\n",
    "        symmetric_cmap=True\n",
    "        cmap='cold_hot'\n",
    "    save_dir=f'../outputs/figures/{dataset}/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)    \n",
    "    if data_type == '59k':\n",
    "        flatmeshes=load_flatmaps_59k() #load flatmaps\n",
    "        surf_path_msm = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.L.inflated_1.6mm_MSMAll.59k_fs_LR.surf.gii'\n",
    "        mesh59k_msm = load_meshes(example_filename=surf_path_msm) #load other meshes\n",
    "        # get data from results in plotting format\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0, vertex_info=vertex_info)\n",
    "        \n",
    "        alpha_cortex_dataL = hcp.left_cortex_data(data_alpha, fill=0, vertex_info=vertex_info)\n",
    "        alpha_cortex_dataR = hcp.right_cortex_data(data_alpha, fill=0, vertex_info=vertex_info)\n",
    "        \n",
    "        # sulcal depth paths\n",
    "        sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "        sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "        # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,alpha_cortex_dataL,flatmeshes.flat_left,sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,alpha_cortex_dataR,flatmeshes.flat_right,sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,alpha_cortex_dataL,mesh59k_msm.very_inflated_left,sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,alpha_cortex_dataR,mesh59k_msm.very_inflated_right,sulc_right,'right'),\\\n",
    "        ]\n",
    "    elif data_type == '32k':\n",
    "        score_cortex_dataL = hcp.left_cortex_data(scores, fill=0)\n",
    "        score_cortex_dataR = hcp.right_cortex_data(scores, fill=0)\n",
    "    #     # sulcal depth paths\n",
    "    #     sulc_left = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.L.sulc.59k_fs_LR.shape.gii'\n",
    "    #     sulc_right = '../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/MNINonLinear/fsaverage_LR59k/100610.R.sulc.59k_fs_LR.shape.gii'\n",
    "    #     # params for view to plot\n",
    "        params = [('flat_L',score_cortex_dataL,alpha_cortex_dataL,hcp.mesh.flat_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('flat_R',score_cortex_dataR,hcp.mesh.flat_right,hcp.mesh.sulc_right,'right'),\\\n",
    "         ('vinf_L',score_cortex_dataL,alpha_cortex_dataR,alpha_cortex_dataL,hcp.mesh.very_inflated_left,hcp.mesh.sulc_left,'left'),\\\n",
    "         ('vinf_R',score_cortex_dataR,alpha_cortex_dataR,hcp.mesh.very_inflated_right,hcp.mesh.sulc_right,'right'),\\\n",
    "        ]\n",
    "    # plot each hemi and mesh, save to outputs dir\n",
    "    for name, data, alpha, mesh, sulc, hemi in params:\n",
    "        alpha = np.where(alpha<0,0,alpha)\n",
    "        alpha = np.where(alpha>1,1,alpha)*2\n",
    "        #figure, axes = plt.subplots(subplot_kw=dict(projection=\"3d\"), figsize=(6,4))\n",
    "        plot_surf(mesh,\\\n",
    "                data, \\\n",
    "                  cmap=cmap,symmetric_cmap=symmetric_cmap, avg_method='median',#figure=fig,\\\n",
    "                bg_map=sulc, colorbar=True, vmin=v[0], vmax=v[1], threshold=threshold, hemi=hemi, \\\n",
    "#                data_alpha=np.where(data_alpha<0,0,data_alpha),\\\n",
    "                data_alpha=np.where(alpha<0,0,alpha),\\\n",
    "                data_remove=np.zeros(data.shape),output_file=f'{scratch_dir}/{name}.png')\n",
    "#combine saved maps into one with PIL\n",
    "#     if notebook==True:\n",
    "    area = (75, 140, 635, 560) #area to crop from each image\n",
    "#     else:\n",
    "#         area = (105, 190, 880, 780)\n",
    "        \n",
    "    img = Image.open(f'{scratch_dir}/flat_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    cropped = img.crop(area)\n",
    "    fL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    w,h = img.size\n",
    "    c_area = (690, 0, w-10, h) # area of colorbar to crop\n",
    "    cbar = img.crop(c_area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/flat_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    fR = img.crop(area)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_L.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iL = img.crop(area)\n",
    "    #iL=cropped.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    img = Image.open(f'{scratch_dir}/vinf_R.png',mode='r')\n",
    "    img = img.resize((770,720))\n",
    "    iR = img.crop(area)\n",
    "\n",
    "    w,h=iR.size\n",
    "\n",
    "    new_im = Image.new('RGB', ( (w*2)+70 , h*2) ,(255, 255, 255, 1))\n",
    "    new_im.paste(fL,(0,h))\n",
    "    new_im.paste(fR,(w,h))\n",
    "    new_im.paste(iL,(0,0))\n",
    "    new_im.paste(iR,(w,0))\n",
    "    new_im.paste(cbar,(w*2,int(round(h/4))))\n",
    "\n",
    "    w,h=new_im.size\n",
    "\n",
    "    draw = ImageDraw.Draw(new_im)\n",
    "    draw.text((0,0),f\"{title}_{subject}_{feature}_{score_type}\",(0,0,0))\n",
    "\n",
    "    new_im.save(f'{save_dir}{title}_{subject}_{feature}_{score_type}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181dc256-aa16-4159-8c48-917c90da4def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[-0.73010646 -0.63736212 -0.62569156 ...  1.80473028  1.8320359\n",
      "  1.86027779]\n",
      "[-0.8171861  -0.69420576 -0.66384539 ...  1.88817272  1.9233567\n",
      "  1.98140834]\n",
      "[-0.73010646 -0.63736212 -0.62569156 ...  1.80473028  1.8320359\n",
      "  1.86027779]\n",
      "[-0.8171861  -0.69420576 -0.66384539 ...  1.88817272  1.9233567\n",
      "  1.98140834]\n"
     ]
    }
   ],
   "source": [
    "#plot_results(music_weight,scores,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_music_weight_alpha')\n",
    "#plot_results(speech_weight,scores,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_speech_weight_alpha')\n",
    "plot_results(animal_weight,scores,'raw','59k',vertex_info,subject,feature,dataset,'ridgeCV_animal_weight_alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e109979b-6c1f-40b6-b730-594d3f3c50b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170494, 521)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adf967db-2503-426b-8080-713c61ba6bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170494,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely=np.argmax(weights,axis=1)\n",
    "most_likely.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4a9ae32-946b-4539-a204-e0bbfbd201f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_classes = np.load('../../speech_face_analysis/notebooks/data/as_classes.npy')\n",
    "for i,m in enumerate(most_likely):\n",
    "    most_likely[i]=as_classes[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3564c9f9-0b63-4728-be7f-031fb51d4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_category = []\n",
    "for c in np.unique(as_classes):\n",
    "    c_ind = np.where(as_classes==c)[0] # get indices of each high level as category\n",
    "    #weights_category.append(np.mean(weights[:,c_ind], axis=1)) #append the MEAN weights of each category to the list\n",
    "    weights_category.append(np.max(weights[:,c_ind], axis=1)) #append the MAX weights of each category to the list\n",
    "weights_category=np.asarray(weights_category)\n",
    "most_likely=np.argmax(weights_category,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f71bed-e489-4ae5-b5fd-f57f561c502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load file ../sourcedata/data/human-connectome-project-openaccess/HCP1200/100610/T1w/fsaverage_LR59k/100610.sulc_1.6mm_MSMAll.59k_fs_LR.dscalar.nii with sulcal depth data\n",
      "[0.         0.16666667 0.33333333 0.5        0.66666667 0.83333333\n",
      " 1.        ]\n",
      "[0.         0.16666667 0.33333333 0.5        0.66666667 0.83333333\n",
      " 1.        ]\n",
      "[0.         0.16666667 0.33333333 0.5        0.66666667 0.83333333\n",
      " 1.        ]\n",
      "[0.         0.16666667 0.33333333 0.5        0.66666667 0.83333333\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "plot_results(most_likely,scores,'weights','59k',vertex_info,subject,'',dataset,'ridgeCV_weights_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbe293-c56f-4f14-8005-59c5974a14ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
