{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to remove confounds from a cifti image and apply LPF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be 2 functions for removing confounds, filtering, etc:\n",
    "\n",
    "- https://nilearn.github.io/modules/generated/nilearn.image.clean_img.html\n",
    "- https://nilearn.github.io/modules/generated/nilearn.signal.clean.html\n",
    "\n",
    "Here I will apply clean_img to the cifti data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(\"paper\", \"white\")\n",
    "\n",
    "from nilearn.image import load_img\n",
    "from nilearn.image import clean_img\n",
    "from nilearn.image import smooth_img\n",
    "from nilearn.image import index_img\n",
    "from nilearn.signal import clean\n",
    "from os import walk\n",
    "\n",
    "from utility import var_to_nan\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel import cifti2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a sub whole brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainpath='/om2/user/jsmentch/projects/nat_img/sourcedata/data/budapest/brain/sub-sid000007_task-movie_run-1_space-fsLR_den-91k_bold.dtseries.nii'\n",
    "brainimg = load_img(brainpath) # load func img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "confound_path = '/om2/user/jsmentch/projects/nat_img/sourcedata/data/budapest/brain/sub-sid000007_task-movie_run-1_desc-confounds_timeseries.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(confound_path, sep='\\t')\n",
    "confounds=data[['global_signal', 'csf', 'white_matter','rot_x','rot_y','rot_z','trans_x','trans_y','trans_z']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_data=np.array(brainimg.dataobj)\n",
    "func_data = var_to_nan(func_data,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func_cln = clean_img(func,detrend=True,confounds=confounds,low_pass=0.1,t_r=1.5)\n",
    "func_data_clean = clean(func_data,detrend=True,standardize='zscore',confounds=confounds,low_pass=0.1,t_r=1)\n",
    "func_cln = nib.Cifti2Image(func_data_clean, brainimg.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_cln.to_filename(export_path+sub+'_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fn to load a subject func scan\n",
    "# def load_sub_data(sub):\n",
    "#     directory_string = \"/om2/user/jsmentch/data/datalad/ds001110/derivatives/fmriprep_old/\" + sub + \"/func/\"\n",
    "#     nifti_file = \"_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\"\n",
    "#     #load subject's functional data\n",
    "#     nii_file = directory_string + sub + nifti_file\n",
    "#     brainimg = load_img(nii_file) # load func img\n",
    "#     return brainimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list of all subjects\n",
    "# #subject_list = list(walk(\"/om2/user/jsmentch/neuroscout/out/wl8RX/fitlins\"))[0][1][:-1] #exclude last sub-36\n",
    "# subject_list = list(walk(\"/om2/user/jsmentch/neuroscout/out/wl8RX/fitlins\"))[0][1]\n",
    "# subject_list = subject_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_list.remove('sub-21') # exclude subject 21 because their data is not there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sub in subject_list:\n",
    "#     func = load_sub_data(sub)\n",
    "#     print(func.shape)\n",
    "# #sub = subject_list[1] #first sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out on one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 91282)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub = 'sub-19'\n",
    "# func = load_sub_data(sub)\n",
    "# func.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confound_path = \"/om2/user/jsmentch/data/datalad/ds001110/derivatives/fmriprep_old/\" + sub + \"/func/\" + sub + \"_task-MerlinMovie_desc-confounds_regressors.tsv\"\n",
    "# data = pd.read_csv(confound_path, sep='\\t')\n",
    "# confounds=data[['global_signal', 'csf', 'white_matter','rot_x','rot_y','rot_z','trans_x','trans_y','trans_z']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean_img: detrend, remove confounds, low pass at 0.1 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nilearn doesn't support cifti for clean_img so use clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_data=np.array(func.dataobj)\n",
    "func_data = var_to_nan(func_data,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func_cln = clean_img(func,detrend=True,confounds=confounds,low_pass=0.1,t_r=1.5)\n",
    "func_data_clean = clean(func_data,detrend=True,standardize='zscore',confounds=confounds,low_pass=0.1,t_r=1.5)\n",
    "func_cln = nib.Cifti2Image(func_data_clean, func.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nibabel.cifti2.cifti2.Cifti2Image object at 0x2b8d52572910>\n"
     ]
    }
   ],
   "source": [
    "print(func_cln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do this for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sub(sub):\n",
    "    #load confounds for each subject\n",
    "    confound_path = \"/om2/user/jsmentch/data/datalad/ds001110/derivatives/fmriprep_old/\" + sub + \"/func/\" + sub + \"_task-MerlinMovie_desc-confounds_regressors.tsv\"\n",
    "    data = pd.read_csv(confound_path, sep='\\t')\n",
    "    confounds=data[['global_signal', 'csf', 'white_matter','rot_x','rot_y','rot_z','trans_x','trans_y','trans_z']].to_numpy()\n",
    "    func = load_sub_data(sub) #load cifti\n",
    "    #clean\n",
    "    func_data=np.array(func.dataobj)\n",
    "    func_data = var_to_nan(func_data,0.5)\n",
    "    #func_cln = clean_img(func,detrend=True,confounds=confounds,low_pass=0.1,t_r=1.5)\n",
    "    func_data_clean = clean(func_data,detrend=True,standardize='zscore',confounds=confounds,low_pass=0.1,t_r=1.5)\n",
    "    func_cln = nib.Cifti2Image(func_data_clean, func.header)\n",
    "    #smooth 2mm\n",
    "    #func_cln_smth = smooth_img(func_cln,2)\n",
    "    return func_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting sub-19\n",
      "exporting sub-20\n",
      "exporting sub-21\n",
      "exporting sub-22\n",
      "exporting sub-23\n",
      "exporting sub-24\n",
      "exporting sub-25\n",
      "exporting sub-26\n",
      "exporting sub-27\n",
      "exporting sub-28\n",
      "exporting sub-29\n",
      "exporting sub-30\n",
      "exporting sub-31\n",
      "exporting sub-32\n",
      "exporting sub-33\n",
      "exporting sub-34\n",
      "exporting sub-35\n",
      "exporting sub-36\n"
     ]
    }
   ],
   "source": [
    "export_path = '/om2/user/jsmentch/projects/speech_face_analysis/data/cifti/cleaned/'\n",
    "for sub in subject_list:\n",
    "    func_cln = clean_sub(sub)\n",
    "    print(f'exporting {sub}')\n",
    "    func_cln.to_filename(export_path+sub+'_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore below here for ciftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-19_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-20_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-21_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-22_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-23_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-24_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-25_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-26_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-27_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-28_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-29_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-30_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-31_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-32_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-33_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-34_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-35_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii',\n",
       " 'sub-36_clean_smooth_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanpath='../data/cifti/cleaned/smoothed/'\n",
    "subject_flist = list(walk(cleanpath))[0][2:][0]\n",
    "subject_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_f=subject_flist[0]\n",
    "img = nib.load(cleanpath+str(s_f))\n",
    "all_sub_added = img.get_fdata()[0,:]\n",
    "for s_f in subject_flist:\n",
    "    img = nib.load(cleanpath+str(s_f))\n",
    "    X = img.get_fdata()[0,:] #load data from nii\n",
    "    all_sub_added = all_sub_added+X\n",
    "\n",
    "union_ind = np.where(np.isnan(all_sub_added),float('NaN'),1) #array where union is 1 and other is NaN so if you * it to another array it will make things NaN that are not in the union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-19_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-20_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-21_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-22_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-23_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-24_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-25_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-26_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-27_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-28_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-29_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-30_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-31_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-32_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-33_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-34_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-35_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n",
      "sub-36_clean_task-MerlinMovie_space-fsLR_den-91k_bold.dtseries.nii\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "cleanpath='../data/cifti/cleaned/'\n",
    "subject_flist = list(walk(cleanpath))[0][2:][0]\n",
    "braintrain = []\n",
    "braintest = []\n",
    "for s_f in subject_flist:\n",
    "    print(s_f)\n",
    "    img = nib.load(cleanpath+str(s_f))\n",
    "    X = img.get_fdata()*union_ind #load data from nii, set things outside group to NaN\n",
    "    X_t = X[17:] #trim beginning, first 17 TRs\n",
    "    s_brain = X_t[:1009] #trim end to end of film    braintrain.append(s_brain[:-200,:]) #roughly 80 20 split, trim the last 200 TRs of each subject to save as test set\n",
    "    braintrain.append(s_brain[:-200,:])\n",
    "    braintest.append(s_brain[-200:,:])\n",
    "Ybrain_train = np.vstack(braintrain)\n",
    "Ybrain_test = np.vstack(braintest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ybrain_train = np.nan_to_num(Ybrain_train)\n",
    "Ybrain_test = np.nan_to_num(Ybrain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Ybrain_train.npy',Ybrain_train)\n",
    "np.save('data/Ybrain_test.npy',Ybrain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 91282)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.dataobj[0,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to load a subjects cleaned func scan\n",
    "def load_decon_data(sub):\n",
    "    directory_string = '/om2/user/jsmentch/data/brain/merlin/func_clean/' \n",
    "    nifti_file = sub + \"_clean.nii.gz\"\n",
    "    #load subject's functional data\n",
    "    nii_file = directory_string + nifti_file\n",
    "    brainimg = load_img(nii_file) # load func img\n",
    "    return brainimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_sub(sub):\n",
    "    func = load_decon_data(sub)\n",
    "    #clean - double check, are these confounds in the correct format?\n",
    "    func_trim = index_img(func,slice(17, 1026)) #remove the first 17 TRs and the shortest is len 1026 so trim the ends of the others\n",
    "    return func_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Data given cannot be loaded because it is not compatible with nibabel format:\nCifti2Image('/om2/...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-92d21e0750bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1026\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mindex_img\u001b[0;34m(imgs, index)\u001b[0m\n\u001b[1;32m    666\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m109\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \"\"\"\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg_4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;31m# duck-type for pandas arrays, and select the 'values' attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_4d\u001b[0;34m(niimg, return_iterator, dtype)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m--> 355\u001b[0;31m     return check_niimg(niimg, ensure_ndim=4, return_iterator=return_iterator,\n\u001b[0m\u001b[1;32m    356\u001b[0m                        dtype=dtype)\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatialimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         raise TypeError(\"Data given cannot be loaded because it is\"\n\u001b[0m\u001b[1;32m    122\u001b[0m                         \u001b[0;34m\" not compatible with nibabel format:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                         + short_repr(niimg))\n",
      "\u001b[0;31mTypeError\u001b[0m: Data given cannot be loaded because it is not compatible with nibabel format:\nCifti2Image('/om2/..."
     ]
    }
   ],
   "source": [
    "index_img(func,slice(17, 1026))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting sub-19\n",
      "exporting sub-20\n",
      "exporting sub-22\n",
      "exporting sub-23\n",
      "exporting sub-24\n",
      "exporting sub-25\n",
      "exporting sub-26\n",
      "exporting sub-27\n",
      "exporting sub-28\n",
      "exporting sub-29\n",
      "exporting sub-30\n",
      "exporting sub-31\n",
      "exporting sub-32\n",
      "exporting sub-33\n",
      "exporting sub-34\n",
      "exporting sub-35\n"
     ]
    }
   ],
   "source": [
    "export_path = '/om2/user/jsmentch/data/brain/merlin/func_clean_trimmed/'\n",
    "for sub in subject_list:\n",
    "    func_trim = trim_sub(sub)\n",
    "    print(f'exporting {sub}')\n",
    "    func_trim.to_filename(export_path+sub+'_trimmed.nii.gz')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to apply a mask to a nii file\n",
    "def apply_roi_mask(data, mask, template):\n",
    "    #load masks of auditory region\n",
    "    roi_dir = \"/om2/user/jsmentch/data/rois/svnh_ROIS_anatlabels_surf_mni/mni15\\\n",
    "2_te11-te10-te12-pt-pp/\"\n",
    "    roi_mask = load_img(roi_dir + mask)\n",
    "    #Mask\n",
    "    data_masked = apply_mask(data, roi_mask) #apply brain mask to data\n",
    "    return data_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_mni152_template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-79f1f129bfb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mni152_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load mni152 template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubject_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/om2/user/jsmentch/neuroscout/out/wl8RX/fitlins\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroi_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/om2/user/jsmentch/data/rois/svnh_ROIS_anatlabels_surf_mni/mni152_te11-te10-te12-pt-pp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#exclude lh, rh, lh_rh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_mni152_template' is not defined"
     ]
    }
   ],
   "source": [
    "template = load_mni152_template() # load mni152 template\n",
    "\n",
    "subject_list = list(walk(\"/om2/user/jsmentch/neuroscout/out/wl8RX/fitlins\"))[0][1][:-1]\n",
    "roi_list = listdir(\"/om2/user/jsmentch/data/rois/svnh_ROIS_anatlabels_surf_mni/mni152_te11-te10-te12-pt-pp\")[:-3] #exclude lh, rh, lh_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subject_list:\n",
    "    data = load_sub_data(sub)\n",
    "    for mask in roi_list:\n",
    "        data_masked = apply_roi_mask(data, mask, template)\n",
    "        out_dir = \"/om2/user/jsmentch/data/\" + sub + \"/\"\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        save_name = out_dir + sub + \"_\" + mask.split('.')[0] + \"_\" + mask.split\\\n",
    "('.')[1]\n",
    "        np.save(save_name, data_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to process a list of the merlin subjects and masks, apply them all\n",
    "from nilearn.image import load_img\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.masking import apply_mask\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os import listdir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
